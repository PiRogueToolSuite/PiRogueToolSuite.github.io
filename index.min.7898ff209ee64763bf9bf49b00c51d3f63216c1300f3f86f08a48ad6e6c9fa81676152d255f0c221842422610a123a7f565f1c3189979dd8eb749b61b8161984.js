var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/pirogue/overview/",title:"Overview",description:`The PiRogue The PiRogue is a Raspberry Pi-based network router that captures and analyses network traffic in real-time. This hardware component serves as the foundation for the suite\u0026rsquo;s extensive software capabilities, which include:
Network traffic analysis: The PiRogue enables deep packet inspection of network traffic, facilitating the identification of suspicious patterns and potential threats.
Mobile forensic: The PiRogue allows for the consensual extraction and analysis of data from mobile devices, including messages, and application data, providing valuable insights into user activity.`,content:` The PiRogue The PiRogue is a Raspberry Pi-based network router that captures and analyses network traffic in real-time. This hardware component serves as the foundation for the suite\u0026rsquo;s extensive software capabilities, which include:
Network traffic analysis: The PiRogue enables deep packet inspection of network traffic, facilitating the identification of suspicious patterns and potential threats.
Mobile forensic: The PiRogue allows for the consensual extraction and analysis of data from mobile devices, including messages, and application data, providing valuable insights into user activity.
The different ports of the PiRogue - * indicates required connections/elements `}).add({id:1,href:"/docs/pirogue/architecture/",title:"Architecture",description:`The PiRogue network router acts as a packet inspection system (PIS) that is used to detect potentially malicious network traffic of any device connected to its Wi-Fi access-point. It relies on the following components:
NFStream: This component is responsible for capturing and parsing network traffic. It can capture traffic from a variety of sources, including physical interfaces, virtual interfaces, and network taps. NFStream also supports a variety of packet capture formats, including pcap, pcapng, and AF_PACKET.`,content:`The PiRogue network router acts as a packet inspection system (PIS) that is used to detect potentially malicious network traffic of any device connected to its Wi-Fi access-point. It relies on the following components:
NFStream: This component is responsible for capturing and parsing network traffic. It can capture traffic from a variety of sources, including physical interfaces, virtual interfaces, and network taps. NFStream also supports a variety of packet capture formats, including pcap, pcapng, and AF_PACKET. Suricata: This component is a network intrusion detection system (NIDS) that uses detection rules to identify malware and malicious traffic. Suricata supports a variety of detection rules, including rules from Snort and EmergingThreats. Suricata can also be used to generate alerts, which can be sent to a security information and event management (SIEM) system or other tools for further analysis. InfluxDB: This component is a time series database that is used to store and analyze the data collected by NFStream and Suricata. InfluxDB is a highly scalable database that can handle large volumes of data. It also supports a variety of query languages, including SQL, InfluxQL, and Flux. Grafana: This component is a data visualization tool that is used to display the data collected by NFStream and Suricata in a graphical format. Grafana supports a variety of dashboards and visualizations, which can be used to monitor the network traffic and alerts. The architecture of the PiRogue The PiRogue works as follows:
NFStream captures and parses network traffic and aggregates packets into flows. NFStream sends the parsed traffic data to InfluxDB. Suricata uses its detection rules to identify malware and malicious traffic. Suricata sends alerts to InfluxDB when it detects known malicious traffic. InfluxDB stores the alerts and network flows collected by Suricata and NFStream. Grafana displays the data collected by NFStream and Suricata in a graphical format. Analysts can use Grafana to monitor the PiRogue for malicious traffic detection. They can also use Grafana to browse and filter alerts and network flows.
Here is an example of how the PiRogue could be used to detect malware:
A user\u0026rsquo;s device is infected with malware. The malware sends network traffic to a command and control (C2) server. NFStream captures and parses the network traffic. NFStream sends the parsed traffic data to Suricata. Suricata uses its detection rules to identify the malware traffic. Suricata sends an alert to InfluxDB. InfluxDB stores the alert. Grafana displays the alert to the analyst. The analyst investigates the alert and determines that the user\u0026rsquo;s device is infected with malware. The analyst takes steps to remediate the infection. ⚠️ Note that the PiRogue keeps 5 days of history, data older than 5 days is automatically deleted.
`}).add({id:2,href:"/docs/pirogue/hardware/",title:"Hardware",description:`The PiRogue\u0026rsquo;s core hardware consists of a Raspberry Pi 4, a versatile single-board computer, enhanced with a custom-designed HAT (Hardware Attachment on Top). This HAT serves as an expansion board that seamlessly integrates with the Raspberry Pi, providing additional functionalities and enhancing its capabilities. It features a TFT screen, a Real-Time Clock (RTC), and cooling fan control circuitry.
PiRogue HAT # The SPI TFT screen acts as a visual interface, displaying crucial information such as system status, network activity, and security alerts.`,content:`The PiRogue\u0026rsquo;s core hardware consists of a Raspberry Pi 4, a versatile single-board computer, enhanced with a custom-designed HAT (Hardware Attachment on Top). This HAT serves as an expansion board that seamlessly integrates with the Raspberry Pi, providing additional functionalities and enhancing its capabilities. It features a TFT screen, a Real-Time Clock (RTC), and cooling fan control circuitry.
PiRogue HAT # The SPI TFT screen acts as a visual interface, displaying crucial information such as system status, network activity, and security alerts. It provides a real-time overview of the device\u0026rsquo;s operation and facilitates monitoring and troubleshooting.
The I2C Real-Time Clock (RTC) ensures accurate timekeeping, independent of network connectivity or external time sources. This precision timing is essential for maintaining consistent timestamps for security events and ensuring the integrity of network traffic analysis.
The cooling fan control circuitry actively manages the Raspberry Pi\u0026rsquo;s temperature, ensuring optimal performance and preventing overheating. This thermal management is crucial for maintaining system stability and preventing performance throttling under demanding workloads.
The RTC is a Maxim DS3231M that uses the I2C protocol to communicate with operating system though the following GPIOs:
SDA: BCM2 SCL: BCM3 The backup battery is a CR1220 button battery.
The screen is a ST7789 240x240px color TFT screen that uses the SPI protocol to communicate with the operating system through the GPIOs:
MOSI: BCM10 SCK: BCM11 RESET: BCM5 DC: BCM6 The cooling fan is controlled by the operating system using PWM though the GPIO BCM13.
Manufacturing files # The current PiRogue HAT version is v1.0_beta.
Get the KiCad project and manufacturing files on GitHub →
👉 Precision regarding some parts:
the 2x20 header has to be in the tall version, you can buy one from Adafruit use a SPI 240x240 IPS screen like this one use CR1220 battery PiRogue HAT schematic Overview of the HAT PCB 3D view of the HAT PiRogue case # The current PiRogue case version is v1.0_beta.
Get the manufacturing files on GitHub →
To 3D print your PiRogue case, you will need:
either the 4 separate STL files or the one containing the 4 part ready the slice a 3D printer PLA or PETG 3D printing parameters # layer height: 0.2 mm infill: 20% no support material: PETG The entire printing lasts around 3 hours for a complete case.
Assemble the whole PiRogue # To assemble your PiRogue case, you will need:
a Raspberry Pi 4 the PiRogue case parts obviously 1 x M2.5 allen key 12 x M2.5 12mm hex socket bolts - see an example on McMaster 4 x M2.5 25mm female threaded hex standoffs - see an example on McMaster 4 x M2.5 hex nuts - see an example on McMaster 4 M2.5 12mm bolts and 4 M2.5 nuts are used to secure the fan in place. The 4 standoffs are placed between the Raspberry Pi and the hat.
`}).add({id:3,href:"/docs/pirogue/operating-system/",title:"Operating system",description:"The PiRogue runs PiRogueOS which is based on Debian 12 by the time we are writing this document (Dec. 2023). Debian is a renowned Linux distribution recognized for its stability, reliability, and commitment to open-source principles. It serves as a foundational platform for numerous other distributions and is widely adopted in various industries, including enterprise environments, scientific research, and embedded systems. Debian\u0026rsquo;s trustworthiness stems from its long-standing reputation for quality, its rigorous testing and development processes, and its commitment to open and transparent collaboration.",content:`The PiRogue runs PiRogueOS which is based on Debian 12 by the time we are writing this document (Dec. 2023). Debian is a renowned Linux distribution recognized for its stability, reliability, and commitment to open-source principles. It serves as a foundational platform for numerous other distributions and is widely adopted in various industries, including enterprise environments, scientific research, and embedded systems. Debian\u0026rsquo;s trustworthiness stems from its long-standing reputation for quality, its rigorous testing and development processes, and its commitment to open and transparent collaboration.
Debian\u0026rsquo;s stability is attributed to its conservative approach to software updates, ensuring that only thoroughly tested and stable packages are included in its repositories. This emphasis on stability makes Debian a preferred choice for mission-critical systems where reliability is paramount.
Debian\u0026rsquo;s commitment to open-source principles fosters a collaborative development model that leverages the expertise of a vast community of developers and users. This open approach promotes transparency, encourages peer review, and ensures that Debian remains a community-driven project with a focus on quality and security.
Pirogue Tool Suite uses a comprehensive set of software tools for network traffic analysis, device forensics, and threat intelligence gathering. These tools are categorized based on their functionalities:
tcpdump: Captures network traffic and stores it in PCAP files for further analysis. suricata: Detects malicious traffic based on predefined rules and signatures. nfstream: Inspects network traffic in-depth to determine the specific applications involved in each data flow. yara: Applies detection rules to decrypted network traffic, identifying patterns and anomalies. adb: Provides a command-line interface for interacting with Android devices for forensic analysis. libimobiledevice: Enables communication and data extraction from iOS devices for forensic investigations. mvt: Conducts comprehensive device forensic analysis, identifying signs of compromise or spyware infection. frida: Injects code into running applications and processes on a device, enabling dynamic analysis through dynamic instrumentation. sha256: Computes file hashes to check data integrity. Hardware integration # PiRogue OS is a tailored version of Debian mainline, a popular Linux distribution known for its stability and reliability. However, the custom HAT (Hardware Attachment on Top) used in PiRogue requires additional configurations to integrate seamlessly with the Linux kernel. To achieve this compatibility, custom Device Tree Blobs (DTBs) and udev rules have been developed.
Device Tree Blobs (DTBs) are data structures that describe the hardware configuration of a device, providing the kernel with information about its components and their relationships. Custom DTBs for the PiRogue HAT enable the kernel to recognize and properly interact with the HAT\u0026rsquo;s unique hardware components, such as the TFT screen, RTC, and fan control circuitry.
Udev rules, on the other hand, are configuration files that govern how the Linux kernel handles device events and assigns device permissions. Custom udev rules for the PiRogue HAT ensure that the kernel properly detects the HAT\u0026rsquo;s devices, assigns them appropriate permissions, and triggers the necessary actions when events occur.
The definition of the different DTB overlays and udev rules can be reviewed on GitHub:
https://github.com/PiRogueToolSuite/deb-packages/tree/debian-12/pirogue-hat/linux/arm64 https://github.com/PiRogueToolSuite/deb-packages/tree/debian-12/pirogue-screen-st7789-240x240/linux/arm64 By implementing custom DTB overlays and udev rules, PiRogue OS ensures seamless integration between the Raspberry Pi, the custom HAT, and the Linux kernel. This tailored approach enables the PiRogue to operate smoothly within the Debian environment. The Linux Kernel uses the RTC as a reference of time and takes care synchronizing the system time with the RTC one at its boot if NTP is not available.
The generation of the operating system image to be flashed on an SD-card is ensured by Packer. It takes the official Debian image and applies changes such as creating a default user and configuring a PPA. The modifications applied to the official Debian image is available on GitHub https://github.com/PiRogueToolSuite/pirogue-os.
PiRogue features can be installed on a Raspberry Pi as well as on a regular computer equipped with a Wi-Fi interface and an Ethernet interface.
Packaging for PiRogue # All features and software installed on the PiRogue are packaged for Debian. These packages are published on 2 PPAs. One for Raspberry Pi OS 11 and one for Debian 12.
A Personal Package Archive (PPA) serves as a repository for software packages maintained by individuals or teams outside of the official Debian distribution. It allows developers to distribute and update their software independently, providing users with access to newer versions or packages not yet included in Debian\u0026rsquo;s main repositories. PPAs offer a convenient way to access other software but require cautious use as they may not undergo the same rigorous testing as official Debian packages.
PTS’s PPAs contain both PiRogue-specific tools as well as external tools that are not available on official Debian repository.
By the time writing this document, PiRogue-specific packages are:
pirogue-ap to setup the Wi-Fi access point pirogue-base is a meta-package to install all PiRogue-specific packages pirogue-cli to install the PiRogue command line tools pirogue-dashboard to setup the PiRogue dashboard pirogue-eve-collector to configure Suricata and setup the tools managing Suricata alerts pirogue-flow-inspector to setup the deep packet inspection pirogue-hat to setup the HAT of the PiRogue pirogue-maintenance to setup the daily maintenance such as detection rules update pirogue-screen-st7789-240x240 to setup the TFT screen of the HAT pirogue-tools to install all other necessary software such as MVT or Frida We also packaged, for Debian, tools that are not maintained by PTS team:
python3-adb-shell python3-ahocorasick python3-communityid python3-geoip2 python3-iosbackup python3-mvt python3-nskeyedunarchiver python3-nfstream frida All PiRogue-specific packages are defined in the GitHub repository https://github.com/PiRogueToolSuite/deb-package in 2 separate branches: one for Raspberry Pi OS 11 and one for Debian 12.
PiRogue Debian packages can be installed on any compatible hardware running Debian 12 (without graphical environment). The package hardware-detection will be taking care of installing the HAT drivers if the installation is done on a Raspberry Pi.
Installation procedure # Have a look to the guide dedicated to building a PiRogue →
To install PiRogue OS on a Raspberry Pi, it is necessary to download the OS image and to flash it on an SD-card. After the first boot on the SD-card, it is possible to connect to the PiRogue using SSH by running the command
$ ssh pi@pirogue.local the default SSH password is raspberry.
Once connected, the operating system has to be upgraded and the PiRogue installation has been to be completed by running the commands
$ sudo apt update $ sudo apt dist-upgrade $ sudo apt install install pirogue-base And finally reboot the PiRogue with the command
$ sudo reboot To convert a regular PC into a PiRogue, it requires Debian 12 being installed without any graphical environment and to add the PTS PPA with commands
$ sudo curl -o /etc/apt/sources.list.d/pirogue.list https://pts-project.org/debian-12/pirogue.list $ sudo curl -o /etc/apt/trusted.gpg.d/pirogue.asc https://pts-project.org/debian-12/Key.gpg And finally install the PiRogue packages with the commands
$ sudo apt update $ sudo apt install install pirogue-base $ sudo reboot The upgrade of the PiRogue, is done using the command, the same way as a regular operating system upgrade
$ sudo apt update $ sudo apt dist-upgrade $ sudo reboot Instead of delegating the hardware detection to the corresponding package, it is also possible to provision a specific configuration before installing PiRogue packages by specifying the following parameters:
WIFI_NETWORK_NAME: SSID of the Wi-Fi network to created WIFI_NETWORK_KEY: password required to connect to the PiRogue’s Wi-Fi network WIFI_COUNTRY_CODE: 2-letter country code where the PiRogue is located ETH_IFACE: the name of the network interface having access to the Internet WLAN_IFACE: the name of the network interface to setup the Wi-Fi access point on
in the file /var/lib/pirogue/config/pirogue.user.env
Upgrade # All PiRogue features are bundled as Debian packages. So, by upgrading Debian (which is the only supported operating system) you are also upgrading your PiRogue.
To upgrade both the OS and the PiRogue features, run the following two commands:
sudo apt update sudo apt dist-upgrade This operation could take some time and would require a reboot to make your PiRogue operates properly.
How often? # We advice you to upgrade your PiRogue weekly.
Heavily customized PiRogue # Some users would want to customize their PiRogue by playing with the different configuration files of the system. If so, be sure to backup your changes BEFORE upgrading your PiRogue. The upgrade will override your customization.
The following configuration files are managed by the PiRogue packages:
/etc/hostapd/hostapd.conf /etc/dnsmasq.conf /etc/dhcpcd.conf /etc/iptables/rules.v4 /etc/iptables/rules.v6 /etc/suricata/suricata.yaml /etc/grafana/grafana.ini /etc/grafana/provisioning/datasources/datasources.yml /etc/grafana/provisioning/dashboards/grafana_dashboards.yml /var/lib/grafana/dashboards/pirogue-dashboard.json /var/lib/grafana/dashboards/pirogue-flow-details-dashboard.json `}).add({id:4,href:"/docs/pirogue/telemetry/",title:"Telemetry",description:`Why? # The telemetry is used to measure the adoption of the project, but also to get some information about the hardware used and thus anticipate the support of widely used but not yet fully supported hardware. Telemetry data is collected on a daily basis.
The collected data is stored for a year on a server managed by us, hosted by Hetzner in Germany.
How to opt-out # You can use the command`,content:`Why? # The telemetry is used to measure the adoption of the project, but also to get some information about the hardware used and thus anticipate the support of widely used but not yet fully supported hardware. Telemetry data is collected on a daily basis.
The collected data is stored for a year on a server managed by us, hosted by Hetzner in Germany.
How to opt-out # You can use the command
sudo pirogue-telemetry config disable You can also delete the entire package with the command:
sudo apt purge pirogue-telemetry How to get the data being deleted # To get the data we collected about your PiRogue being deleted, reach out to us by email at hello@pts-project.org and specify the ID or the sha256 of the ID of your PiRogue.
You can find the ID (unique_id) of your PiRogue by running the command:
sudo pirogue-telemetry config show What data we collect # The unique ID collected corresponds to the sha256 sum of the ID generated at its first launch. The AS and the country where the PiRogue is connected from are determined by making a call to https://ip-info.pts-project.org/json. We do not collect any other data than what\u0026rsquo;s listed here.
Here is an example of the data we collect on a daily basis:
{ \u0026#34;unique_id\u0026#34;: \u0026#34;81f672fe973c6e70acd043b4a4845fa38e7425d290678042b7e72e53661a9347\u0026#34;, \u0026#34;asn\u0026#34;: \u0026#34;3215\u0026#34;, \u0026#34;asn_name\u0026#34;: \u0026#34;Orange\u0026#34;, \u0026#34;country_code\u0026#34;: \u0026#34;FR\u0026#34;, \u0026#34;country_name\u0026#34;: \u0026#34;France\u0026#34;, \u0026#34;os_arch\u0026#34;: \u0026#34;x86_64\u0026#34;, \u0026#34;os_id\u0026#34;: \u0026#34;ubuntu\u0026#34;, \u0026#34;os_name\u0026#34;: \u0026#34;Ubuntu\u0026#34;, \u0026#34;os_type\u0026#34;: \u0026#34;linux\u0026#34;, \u0026#34;os_version\u0026#34;: \u0026#34;22.04\u0026#34; } `}).add({id:5,href:"/docs/pirogue/configuration/",title:"Configuration",description:`⚠️ This documentation requires either
the package pirogue-base version 1.0.2 or more recent being installed the package pirogue-base-pc version 1.0.0 or more recent being installed Not sure? Upgrade your PiRogue.
How the PiRogue configuration works # PiRogue features come in Debian packages, each package manages some system configuration files:
the package pirogue-ap creates the wi-fi access point, it manages: /etc/hostapd/hostapd.conf /etc/dnsmasq.conf /etc/dhcpcd.conf /etc/iptables/rules.v4 /etc/iptables/rules.v6 the package pirogue-dashboard creates the dashboard, it manages: /etc/grafana/grafana.`,content:` ⚠️ This documentation requires either
the package pirogue-base version 1.0.2 or more recent being installed the package pirogue-base-pc version 1.0.0 or more recent being installed Not sure? Upgrade your PiRogue.
How the PiRogue configuration works # PiRogue features come in Debian packages, each package manages some system configuration files:
the package pirogue-ap creates the wi-fi access point, it manages: /etc/hostapd/hostapd.conf /etc/dnsmasq.conf /etc/dhcpcd.conf /etc/iptables/rules.v4 /etc/iptables/rules.v6 the package pirogue-dashboard creates the dashboard, it manages: /etc/grafana/grafana.ini /etc/grafana/provisioning/datasources/datasources.yml /etc/grafana/provisioning/dashboards/grafana_dashboards.yml /var/lib/grafana/dashboards/pirogue-dashboard.json /var/lib/grafana/dashboards/pirogue-flow-details-dashboard.json the package pirogue-eve-collector retrieve alarms from Suricata, it manages: /etc/suricata/suricata.yaml ⚠️ Any changes made manually in these files are overridden when these packages are installed and upgraded. To ease the configuration of your PiRogue, we provide a tool pirogue-ctl which allows you to manage your configuration, create configuration backups, etc.
pirogue-ctl will generate new configuration files for the different services running on your PiRogue and ensure that your configuration is not modified when you upgrade your PiRogue.
To install it, run the following command, it will tell you if the package is already installed:
sudo apt update sudo apt install pirogue-cli Once installed you can run:
sudo pirogue-ctl config show If you have never applied any valid configuration, the command should display Create or modify my own PiRogue configuration # Once you have installed the pirogue-cli package and run sudo pirogue-ctl config show at least once, you can start reconfiguring your PiRogue. To do so, you first have to edit the appropriate configuration file:
sudo nano /var/lib/pirogue/config/pirogue.env it will open a text editor (nano) showing your own configuration file. In this file you can safely change the following options:
WIFI_NETWORK_NAME the name of the wi-fi network managed by your PiRogue, by default PiRogue1 WIFI_NETWORK_KEY the passphrase required to connect to the wi-fi network, by default superlongkey. WIFI_COUNTRY_CODE indicates the country (ISO/IEC 3166-1 format) in which your PiRogue is operating, by default FR DASHBOARD_PASSWORD the password asked when you log in the PiRogue\u0026rsquo;s dashboard, by default PiRogue ⚠️ Do not use \u0026quot;, # or any emoji. Example, we change the name of the wi-fi network for PiRogue11, our configuration file looks like:
WIFI_NETWORK_NAME=PiRogue11 WIFI_NETWORK_KEY=superlongkey WIFI_COUNTRY_CODE=FR WLAN_IFACE=wlan0 ETH_IFACE=eth0 DASHBOARD_PASSWORD=PiRogue Press ctrl+x on your keyboard to exit nano, press y to save your modifications, press n otherwise.
Apply my configuration # Once you have edited the PiRogues\u0026rsquo;s configuration file, run the following command to apply this new configuration:
sudo pirogue-ctl config apply press y to apply your configuration, n otherwise.
Now your configuration has been succesfuly applied. You can see it by running sudo pirogue-ctl config show.
By default, your configuration and all the different configuration files modified by pirogue-ctl have been backed-up.
At any time you can restore a previous configuration by running the command:
sudo pirogue-ctl config restore Check if everything runs properly # To check how healthy your PiRogue is, run
pirogue-ctl status If you see everything in a mix of purple and green, congrats!
`}).add({id:6,href:"/docs/pirogue/network-traffic-analysis/",title:"Network traffic analysis",description:`The PiRogue is designed to continuously analyze the network traffic of any device connected to its Wi-Fi network. This means that it is constantly monitoring and inspecting the data packets that are being transmitted and received by these devices. The purpose of this analysis is to identify any suspicious or malicious activity that may be taking place on the device.
The PiRogue employs two primary methods for analyzing network traffic: NFStream Deep Packet Inspection (DPI) and Suricata rule-based IDS.`,content:`The PiRogue is designed to continuously analyze the network traffic of any device connected to its Wi-Fi network. This means that it is constantly monitoring and inspecting the data packets that are being transmitted and received by these devices. The purpose of this analysis is to identify any suspicious or malicious activity that may be taking place on the device.
The PiRogue employs two primary methods for analyzing network traffic: NFStream Deep Packet Inspection (DPI) and Suricata rule-based IDS.
Deep Packet Inspection (DPI) # DPI is a technique that allows the PiRogue to examine the contents of data packets in detail. This includes information such as the source and destination IP addresses, the ports being used, the type of data being transmitted, and even the identification of the application involved. By analyzing this information, we can identify patterns and anomalies that may indicate malicious activity.
The PiRogue relies on NFStream to carry out the DPI. NFStream is a Python-based framework designed for efficient and flexible network data analysis. It serves as a powerful tool for researchers and network engineers to process and extract insights from network traffic. Its deep packet inspection (DPI) capabilities enable it to delve into the contents of network packets, going beyond basic header information to analyze the payload data. This allows NFStream to identify applications, protocols, and specific content within the traffic flow. With its DPI engine, NFStream can classify encrypted traffic, extract metadata, and fingerprint applications, even when they are hidden within encrypted protocols like TLS or SSH. This deep inspection capability makes NFStream a valuable tool for network traffic classification, anomaly detection, and security analysis.
Threat detection # An intrusion detection system (IDS) is a cybersecurity sentinel that monitors network traffic and system activities to identify potential intrusions or malicious activities. It acts as a vigilant guard, scrutinizing network packets, system logs, and user behavior to detect suspicious patterns or anomalies. IDSs employ various detection techniques, including signature-based, anomaly-based, and behavioral analysis, to identify both known and unknown threats. Upon detecting a potential intrusion, IDSs generate alerts, allowing security teams to investigate and respond promptly to safeguard the network and its assets.
The PiRogue relies on Suricata to detect and identify known threats. Suricata is an open-source intrusion detection system (IDS) and intrusion prevention system (IPS) designed to safeguard network environments against malicious activities. It functions as a vigilant sentinel, scrutinizing network traffic in real-time to detect and thwart potential threats. It employs a multi-faceted approach, combining signature-based detection with advanced anomaly-based techniques to identify both known and unknown threats. It leverages a comprehensive ruleset, continuously updated with the latest threat intelligence, to flag suspicious patterns and behaviors. Additionally, Suricata\u0026rsquo;s deep packet inspection capabilities enable it to scrutinize the contents of network packets, uncovering hidden malware or exploit attempts.
The PiRogue comes pre-configured with rules from ProofPoint Emerging Threat Open and Echap, two reputable sources of threat intelligence. The PiRogue update those rules on a daily basis.
Visualizing analysis results # The results of the PiRogue’s automatic network traffic analysis can be visualized in the dashboard. This dashboard provides a graphical overview of the network traffic that has been analyzed, as well as any threats that have been detected. The dashboard also allows users to drill down into the details of specific network flows to learn more about them.
`}).add({id:7,href:"/docs/pirogue/dashboard/",title:"Dashboard",description:`By default, the PiRogue exposes a Grafana dashboard at the address http://pirogue.local:3000 showing in real-time the ongoing network connections, security alerts and other information. The default dashboard is composed of different panels.
Overview of the PiRogue dashboard Have a look to the guide dedicated to the PiRogue dashboard →
General statistics # General statistics panel provides a comprehensive overview of network activity and security events within the selected timeframe. It presents a detailed breakdown of the following metrics:`,content:`By default, the PiRogue exposes a Grafana dashboard at the address http://pirogue.local:3000 showing in real-time the ongoing network connections, security alerts and other information. The default dashboard is composed of different panels.
Overview of the PiRogue dashboard Have a look to the guide dedicated to the PiRogue dashboard →
General statistics # General statistics panel provides a comprehensive overview of network activity and security events within the selected timeframe. It presents a detailed breakdown of the following metrics:
Connected devices: The panel displays the total number of unique devices that have connected to the PiRogue\u0026rsquo;s Wi-Fi network during the selected period. Security alerts: The panel highlights the number of security alerts triggered by Suricata rules during the selected period. These alerts indicate potential intrusion attempts, malicious activities, or policy violations. Network I/O: The panel showcases the total amount of network traffic exchanged between connected devices and the Internet during the selected period. This metric reflects the overall network bandwidth consumption and data transfer activity. Network flows: The panel exhibits the total number of network flows that have occurred during the selected period. Network flows represent individual communication sessions between devices, providing insights into network usage patterns and application behavior. World map panel displays the location of the different servers the connected devices have been communicating with during the selected period of time.
Network flows # Network flows panel provides a comprehensive overview of network flows that have occurred during the specified timeframe. It presents detailed information about each flow, including:
The exact time at which the flow commenced The traffic category as determined by NFStream\u0026rsquo;s classification engine The type of application responsible for generating the flow The domain name of the server that was contacted during the flow The IP address of the flow\u0026rsquo;s source, indicating the originating device The IP address of the flow\u0026rsquo;s destination, indicating the target server The country where the remote server is geographically located The total amount of network traffic associated with the flow, indicating its data volume This detailed information allows for in-depth analysis of network activity, enabling security professionals to identify patterns, anomalies, and potential security risks.
Security alerts # Suricata alerts panel provides a comprehensive overview of security alerts generated by Suricata during a specified timeframe. Each alert is presented with detailed information, including:
The timestamp of the alert. Clicking on the timestamp will provide in-depth details about the selected alert. The severity level of the alert, indicating the potential impact and urgency of the detected threat. The type of threat associated with the alert, classifying the nature of the malicious activity or intrusion attempt. The name of the rule that triggered the alert, providing insight into the specific pattern or behavior that raised suspicion. The IP address of the source of the network traffic associated with the alert, identifying the origin of the potential threat or indicating the intended target of the suspicious activity The IP address of the destination of the network traffic associated with the alert, identifying the origin of the potential threat or indicating the intended target of the suspicious activity. This comprehensive presentation of security alerts enables security analysts to quickly assess the severity and nature of potential threats, allowing for prompt investigation and response to safeguard the analyzed device and its assets. ⚠️ Note that the PiRogue keeps 5 days of history, data older than 5 days is automatically deleted.
`}).add({id:8,href:"/docs/pirogue/export-data/",title:"Export data",description:"PiRogue deletes the data every 5 days for security reasons but to do a further analysis it is necessary to extract the alerts and flows as a result of the analysis, to export the data we need to do the following steps.\nOnce connected to the PiRogue, run the command\n$ influx -database \u0026#39;suricata\u0026#39; -execute \u0026#39;SELECT * FROM \u0026#34;suricata\u0026#34;.\u0026#34;suricata_5d\u0026#34;.\u0026#34;alert\u0026#34;\u0026#39; -format \u0026#39;csv\u0026#39; alerts-`date +\u0026#34;%Y-%m-%d\u0026#34;`.csv to export all Suricata alerts in a CSV file.",content:`PiRogue deletes the data every 5 days for security reasons but to do a further analysis it is necessary to extract the alerts and flows as a result of the analysis, to export the data we need to do the following steps.
Once connected to the PiRogue, run the command
$ influx -database \u0026#39;suricata\u0026#39; -execute \u0026#39;SELECT * FROM \u0026#34;suricata\u0026#34;.\u0026#34;suricata_5d\u0026#34;.\u0026#34;alert\u0026#34;\u0026#39; -format \u0026#39;csv\u0026#39; alerts-\`date +\u0026#34;%Y-%m-%d\u0026#34;\`.csv to export all Suricata alerts in a CSV file.
Run the command
$ influx -database \u0026#39;flows\u0026#39; -execute \u0026#39;SELECT * FROM \u0026#34;flows\u0026#34;.\u0026#34;flows_5d\u0026#34;.\u0026#34;flow\u0026#34;\u0026#39; -format \u0026#39;csv\u0026#39; flows-\`date +\u0026#34;%Y-%m-%d\u0026#34;\`.csv to export all network flows in a CSV file.
You can then use scp to save these 2 files on your computer. Once you have retrieved your CSV files, you can open them with Excel, LibreOffice or any other software supporting CSV format.
The influxdb queries listed above are pretty simple but you can adapt them to your specific need, check out the influxdb documentation.
You can refine your request by filtering the following fields of the flows database:
time: timestamp in nanoseconds on first flow bidirectional packet application_category_name: nDPI detected application category name application_name: nDPI detected application name bidirectional_bytes: flow bidirectional bytes accumulator bidirectional_duration_ms: flow bidirectional duration in milliseconds city: city determined by geoip based on the remote IP address community_id: community ID community_id_b64: community ID encoded in base64 country: country name determined by geoip based on the remote IP address country_iso: country ISO code determined by geoip based on the remote IP address dst2src_bytes: flow destination to source bytes accumulator dst_ip: destination IP address string representation dst_mac: destination MAC address string representation dst_port: transport layer destination port latitude: latitude determined by geoip based on the remote IP address longitude: longitude determined by geoip based on the remote IP address requested_server_name: requested server name (SSL/TLS, DNS, HTTP) src2dst_bytes: flow source to destination bytes accumulator src_ip: source IP address string representation src_mac: source MAC address string representation src_port: transport layer source port You can refine your request by filtering the following fields of the Suricata alerts database:
time: timestamp in nanoseconds on detection alert_category: category of the triggered rule alert_severity: alert severity alert_signature: signature of the triggered rule alert_signature_id: unique identifier of the triggered rule app_proto: network protocol (dns, http…) community_id: community ID community_id_b64: community ID encoded in base64 dest_ip: destination IP address string representation dest_port: transport layer destination port in_iface: network interface name proto: transport protocol (UDP, TCP) src_ip: source IP address string representation src_port: transport layer source port `}).add({id:9,href:"/docs/pirogue/consensual-device-forensic/",title:"Consensual device forensic",description:"Consensual mobile device forensic analysis is the process of examining a mobile device with the owner\u0026rsquo;s consent to identify signs of compromise or active spying. This involves analyzing data stored on the device, such as call logs, text messages, and browsing history, as well as examining installed apps and system configurations. The goal is to uncover any unauthorized access, surveillance activities, or malicious software that may be compromising the device\u0026rsquo;s security and privacy.",content:`Consensual mobile device forensic analysis is the process of examining a mobile device with the owner\u0026rsquo;s consent to identify signs of compromise or active spying. This involves analyzing data stored on the device, such as call logs, text messages, and browsing history, as well as examining installed apps and system configurations. The goal is to uncover any unauthorized access, surveillance activities, or malicious software that may be compromising the device\u0026rsquo;s security and privacy.
The PiRogue comes with MVT pre-installed. Amnesty International\u0026rsquo;s Mobile Verification Toolkit (MVT) is an open-source software tool designed for consensual mobile device forensics. It helps investigators and security researchers analyze Android and iOS devices to detect potential signs of compromise, particularly from sophisticated spyware like Pegasus. The tool utilizes indicators of compromise (IOCs) to scan device backups and identify traces of spyware infection or targeting. MVT is primarily intended for technical experts and is not designed for end-user self-assessment.
For more details about MVT, please check its official documentation: https://docs.mvt.re
Have a look to the guide dedicated to device backup →
Have a look to the guide dedicated to MVT →
`}).add({id:10,href:"/docs/pirogue/capture-network-traffic/",title:"Capture network traffic",description:`With the PiRogue, it is quite easy to capture the entire network traffic of any device connected to its Wi-Fi network. To capture the network traffic, we use the command tcpdump.
Have a look to the guide dedicated to capturing network traffic →
The command
$ tcpdump -i wlan0 -w capture.pcap instructs the tcpdump utility to capture network traffic from the wireless interface wlan0 and store the captured data in a file named capture.`,content:`With the PiRogue, it is quite easy to capture the entire network traffic of any device connected to its Wi-Fi network. To capture the network traffic, we use the command tcpdump.
Have a look to the guide dedicated to capturing network traffic →
The command
$ tcpdump -i wlan0 -w capture.pcap instructs the tcpdump utility to capture network traffic from the wireless interface wlan0 and store the captured data in a file named capture.pcap.
tcpdump is a network packet analyzer that allows users to capture and inspect network traffic in real-time. It operates by directly interacting with the network interface card (NIC) and capturing the raw data packets that flow through it. These packets contain information about the source and destination of the communication, the type of protocol used, and the data being transmitted.
PCAP (Packet Capture) is a file format specifically designed for storing captured network traffic. It encapsulates the raw data packets in a structured format, preserving the packet headers, payload data, and timestamps. PCAP files serve as valuable sources of information for network troubleshooting, performance analysis, and security investigations.
In this specific command, -i wlan0 specifies the network interface to monitor, which in this case is the wireless interface wlan0 of the PiRogue. The -w capture.pcap option instructs tcpdump to write the captured packets to a file named capture.pcap in the PCAP format. Once the capture is complete, the resulting PCAP file can be analyzed using various network analysis tools such as Wireshark to gain insights into network behavior, identify anomalies, or investigate security incidents.
`}).add({id:11,href:"/docs/prologue/introduction/",title:"Introduction",description:"The PiRogue Tool Suite is an open-source consensual digital forensic analysis and incident response solution that empowers organizations with comprehensive tools for network traffic analysis, mobile forensics, knowledge management, and artifact handling. The tool suite includes both hardware and software components, with the PiRogue network router and its Colander case management platform. Thanks to its open-source and comprehensive nature, its user-friendly design and modular flexibility, its community support, the PiRogue tool suite has become an attractive option for organizations seeking a cost-effective solution for digital investigations.",content:`The PiRogue Tool Suite is an open-source consensual digital forensic analysis and incident response solution that empowers organizations with comprehensive tools for network traffic analysis, mobile forensics, knowledge management, and artifact handling. The tool suite includes both hardware and software components, with the PiRogue network router and its Colander case management platform. Thanks to its open-source and comprehensive nature, its user-friendly design and modular flexibility, its community support, the PiRogue tool suite has become an attractive option for organizations seeking a cost-effective solution for digital investigations.
Get help on our Discord →
`}).add({id:12,href:"/docs/pirogue/mobile-app-analysis/",title:"Mobile app analysis",description:"Have a look to the guide dedicated to this topic →",content:`Have a look to the guide dedicated to this topic →
`}).add({id:13,href:"/docs/prologue/overview/",title:"Overview",description:`At the core of the PiRogue Tool Suite lies the PiRogue hardware device, a Raspberry Pi based network router that captures and analyzes network traffic in real-time. This hardware component serves as the foundation for the suite\u0026rsquo;s extensive software capabilities, which include:
Network traffic analysis: The PiRogue enables deep packet inspection of network traffic, facilitating the identification of suspicious patterns and potential threats.
Mobile forensic: The PiRogue allows for the consensual extraction and analysis of data from mobile devices, including messages and application data, providing valuable insights into the system activity.`,content:`At the core of the PiRogue Tool Suite lies the PiRogue hardware device, a Raspberry Pi based network router that captures and analyzes network traffic in real-time. This hardware component serves as the foundation for the suite\u0026rsquo;s extensive software capabilities, which include:
Network traffic analysis: The PiRogue enables deep packet inspection of network traffic, facilitating the identification of suspicious patterns and potential threats.
Mobile forensic: The PiRogue allows for the consensual extraction and analysis of data from mobile devices, including messages and application data, providing valuable insights into the system activity.
Mobile app and malware analysis: The PiRogue is capable of dynamically instrumenting mobile applications and operating system to trace all network communication, data collection and cryptographic operations, providing evidence of data transmission and malicious activities.
The PiRogue Tool Suite\u0026rsquo;s capabilities are complemented by the Colander web platform, a case and incident response management platform that integrates seamlessly with the hardware and software components. Colander provides a centralized hub for managing investigations, streamlining workflows, and enabling collaboration among team members.
Knowledge management: Colander facilitates the organization and sharing of investigative knowledge, ensuring that insights are readily available to team members, promoting collaboration and efficiency.
Artifact management: Colander streamlines the handling and preservation of digital evidence, maintaining chain of custody and facilitating admissibility in legal proceedings.
Digital investigation: Colander simplifies the digital investigation process, offering a central platform for case management, evidence handling, gathering threat intelligence for 3rd-party, collaboration, and network traffic analysis.
The PiRogue Tool Suite offers several key advantages that make it an attractive option for organizations seeking a comprehensive and cost-effective solution for digital investigations:
Open-source: The open-source nature of the project makes it accessible to organizations with limited budgets, removing financial barriers to acquiring powerful investigative tools.
Comprehensive toolset: The suite provides a wide range of tools for both mobile forensics and network traffic analysis, catering to diverse investigative needs and ensuring thoroughness in evidence collection.
User-friendly design: The user interface is designed to be intuitive and straightforward, even for non-technical users, minimizing the learning curve and enabling an efficient adoption.
Modular flexibility: The modular design allows for easy integration with existing systems and workflows, facilitating compatibility with existing infrastructure and processes.
Community support: The active open-source community provides ongoing support and development, ensuring that the suite remains up-to-date and continuously improves and adapts to evolving needs.
👉 The PiRogue can be used without Colander. `}).add({id:14,href:"/docs/prologue/philosophy/",title:"Philosophy",description:"We advocate for the democratization of information security tools and threat intelligence, transforming them from exclusive proprietary assets of a select few companies into widely accessible public goods. By embracing open-source principles and fostering collaborative development, we aim to empower individuals and organizations worldwide with the knowledge and tools that are necessary to safeguard their digital assets. Our approach promotes transparency, fosters innovation, and ensures that the benefits of cybersecurity are not confined to a privileged few but are shared among the broader community.",content:`We advocate for the democratization of information security tools and threat intelligence, transforming them from exclusive proprietary assets of a select few companies into widely accessible public goods. By embracing open-source principles and fostering collaborative development, we aim to empower individuals and organizations worldwide with the knowledge and tools that are necessary to safeguard their digital assets. Our approach promotes transparency, fosters innovation, and ensures that the benefits of cybersecurity are not confined to a privileged few but are shared among the broader community. To foster widespread adoption and establish a foundation of trust, this project exclusively uses established open-source tools that are widely recognized and trusted within the cybersecurity industry. Our commitment to open-source solutions promotes transparency, collaboration, and community-driven development, and furthermore ensures that the project benefits from the collective expertise and scrutiny of cybersecurity community. By leveraging industry-standard tools, the project aims to instill confidence in its capabilities and encourage widespread adoption among security-conscious organizations.
`}).add({id:15,href:"/docs/prologue/background/",title:"Background",description:`PiRogue Tool Suite project is the reboot of the PiRanhaLysis project. PTS is founded by Defensive Lab Agency with the financial support of Open Technology Fund.
Defensive Lab Agency (DLA) is a French company founded in 2018 by Esther Onfroy with the objective of providing expert services on digital security and privacy issues. DLA is specialized in mobile security and focuses its work on supporting NGOs, activists, journalists, human rights defenders and public institutions against digital surveillance.`,content:`PiRogue Tool Suite project is the reboot of the PiRanhaLysis project. PTS is founded by Defensive Lab Agency with the financial support of Open Technology Fund.
Defensive Lab Agency (DLA) is a French company founded in 2018 by Esther Onfroy with the objective of providing expert services on digital security and privacy issues. DLA is specialized in mobile security and focuses its work on supporting NGOs, activists, journalists, human rights defenders and public institutions against digital surveillance.
Since 2018, DLA\u0026rsquo;s major public contributions were reverse engineering of FinSpy Android for Amnesty International, conducting privacy analysis of edtech mobile apps for Human Rights Watch and hosting mobile forensic online courses for Digital Defender Partnership.
The services DLA specializes in are:
Reverse engineering of Android apps and malware: this includes decompiling the app to its source code, analyzing the code for malicious behavior, and identifying its vulnerabilities. DLA can also help to develop secure Android apps by providing feedback on your code and recommending security best practices.
Consensual mobile forensic analysis: DLA can investigate security incidents involving mobile devices. This includes extracting and analyzing data from mobile devices to identify evidence of malicious activity.
Mobile app privacy analysis: DLA can help understand how mobile apps collect and process user data. This includes reviewing the app\u0026rsquo;s privacy policy, analyzing the app\u0026rsquo;s code, and testing the app\u0026rsquo;s behavior. DLA can also help develop privacy-friendly mobile apps by providing recommendations on how to collect and process user data in a responsible manner.
Regulatory compliance audits of Android apps: DLA can help ensure that apps comply with regulations, e.g. the General Data Protection Regulation (GDPR). This would require reviewing the app\u0026rsquo;s privacy policy, analyzing the app\u0026rsquo;s code, and testing the app\u0026rsquo;s behavior.
Mobile security and forensic training: DLA offers trainings to increase security awareness and practices. DLA also offers trainings on how to best take advantage of our open source tools.
The PTS project is developed and maintained by Esther Onfroy. Expert in information security and reverse engineering, Esther Onfroy, aka U039b, is a French hacktivist and lecturer. She is also co-founder of Defensive Lab Agency, Exodus Privacy (French non-profit organization that fights against tracking SDKs in Android apps), Pithus (open source mobile threat intelligence platform), Echap (French non-profit organization that fights against the use of technology in violence against women), La Résille (French non-profit organization of hackers producing feminist science-fiction). She fights against surveillance capitalism and has contributed to several investigations highlighting the illegal data collection carried out by major digital actors. She helps journalists, academics and NGOs to better understand the issues of cybersecurity and surveillance on mobile devices.
Esther works closely with the LGBTQ+ community on creating tools and protocols that fight against gender based violence facilitated by information and communication technologies. With Echap, she works with women’s shelters. She has been working with NGOs and HRDs for 8 years.
More details about her activities at https://esther.codes.
`}).add({id:16,href:"/docs/pirogue/cheatsheet/",title:"Cheatsheet",description:`Default configuration # Name Value Example of usage SSH port 22 ssh -p22 pi@\u0026lt;PiRogue IP address\u0026gt; SSH user pi SSH password raspberry Dashboard port 3000 http://\u0026lt;PiRogue IP address\u0026gt;:3000 Dashboard user admin Dashboard password PiRogue Wi-Fi SSID PiRogue1 Wi-Fi password superlongkey Chronograph port 8888 http://\u0026lt;PiRogue IP address\u0026gt;:8888 To see your configuration, run
sudo pirogue-ctl config show Important files # Name Location SSH configuration /etc/ssh/sshd_config PiRogue configuration /var/lib/pirogue/config/pirogue.env Suricata rules /var/lib/suricata/rules/suricata.rules `,content:`Default configuration # Name Value Example of usage SSH port 22 ssh -p22 pi@\u0026lt;PiRogue IP address\u0026gt; SSH user pi SSH password raspberry Dashboard port 3000 http://\u0026lt;PiRogue IP address\u0026gt;:3000 Dashboard user admin Dashboard password PiRogue Wi-Fi SSID PiRogue1 Wi-Fi password superlongkey Chronograph port 8888 http://\u0026lt;PiRogue IP address\u0026gt;:8888 To see your configuration, run
sudo pirogue-ctl config show Important files # Name Location SSH configuration /etc/ssh/sshd_config PiRogue configuration /var/lib/pirogue/config/pirogue.env Suricata rules /var/lib/suricata/rules/suricata.rules `}).add({id:17,href:"/docs/pirogue/useful-commands/",title:"Useful commands",description:`Find the IP address of your PiRogue # On your computer connected to the same network as your PiRogue, run the following command:
ping -c1 pirogue.local Example of output, in this example, the IP address of the PiRogue is 192.168.0.16:
PING pirogue.local (192.168.0.16) 56(84) bytes of data. 64 bytes from pirogue.home (192.168.0.16): icmp_seq=1 ttl=64 time=0.319 ms --- pirogue.local ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.`,content:`Find the IP address of your PiRogue # On your computer connected to the same network as your PiRogue, run the following command:
ping -c1 pirogue.local Example of output, in this example, the IP address of the PiRogue is 192.168.0.16:
PING pirogue.local (192.168.0.16) 56(84) bytes of data. 64 bytes from pirogue.home (192.168.0.16): icmp_seq=1 ttl=64 time=0.319 ms --- pirogue.local ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.319/0.319/0.319/0.000 ms Connect to your PiRogue with SSH # This section is largely inspired by the Raspberry Pi official documentation.
You can use SSH to connect to your PiRogue from a Linux desktop, another PiRogue, or from an Apple Mac without installing additional software.
Open a terminal window on your computer replacing \u0026lt;PiRogue IP address\u0026gt; with the IP address of the PiRogue you’re trying to connect to,
ssh -p22 pi@\u0026lt;PiRogue IP address\u0026gt; When the connection works you will see a security/authenticity warning. Type yes to continue. You will only see this warning the first time you connect.
👉 If you receive a connection timed out error it is likely that you have entered the wrong IP address for the PiRogue. Next you will be prompted for the password for the pi login: the default password on PiRogue OS is raspberry.
For security reasons it is highly recommended to change the default password on the PiRogue (also, you can not login through ssh if the password is blank). You should now be able to see the PiRogue prompt, which will be identical to the one found on the PiRogue itself.
If you have set up another user on the PiRogue, you can connect to it in the same way, replacing the username with your own, e.g. eben@192.168.1.5
pi@pirogue ~ $ You are now connected to the PiRogue remotely, and can execute commands.
Change your password # On your PiRogue, run the following command and answer the different questions:
passwd Restart PiRogue services # On your PiRogue, run the following command:
sudo systemctl restart pirogue* Restart your PiRogue # On your PiRogue, run the following command:
sudo reboot Shutdown your PiRogue # On your PiRogue, run the following command:
sudo halt `}).add({id:18,href:"/docs/pirogue/pre-installed-tools/",title:"Pre-installed tools",description:`Your PiRogue comes with a set a pre-installed and pre-configured tools covering different purposes.
Network traffic capture # tcpdump to capture network traffic into PCAP files - documentation mitm-proxy to intercept and capture HTTPS traffic - documentation Network traffic analysis # suricata to detect malicious traffic based on rules - documentation nfstream to inspect traffic and determine the application involved in each flow - documentation Device analysis \u0026amp; forensic # adb to interact with Android devices - documentation libimobiledevice to interact with iOS devices - documentation mvt to conduct device forensic analysis - documentation frida to instrument programs running on a device - documentation Data visualization # influxdb to store data generated by nfstream and suricata - documentation chronograph to search and export data stored in influxdb - documentation grafana to display data on dashboards - documentation Utilities # vim to edit files - documentation git to version files - documentation jq to manipulate JSON files - documentation gnupg2 to sign, encrypt and verify files - documentation python3 to write and execute Python programs - documentation `,content:`Your PiRogue comes with a set a pre-installed and pre-configured tools covering different purposes.
Network traffic capture # tcpdump to capture network traffic into PCAP files - documentation mitm-proxy to intercept and capture HTTPS traffic - documentation Network traffic analysis # suricata to detect malicious traffic based on rules - documentation nfstream to inspect traffic and determine the application involved in each flow - documentation Device analysis \u0026amp; forensic # adb to interact with Android devices - documentation libimobiledevice to interact with iOS devices - documentation mvt to conduct device forensic analysis - documentation frida to instrument programs running on a device - documentation Data visualization # influxdb to store data generated by nfstream and suricata - documentation chronograph to search and export data stored in influxdb - documentation grafana to display data on dashboards - documentation Utilities # vim to edit files - documentation git to version files - documentation jq to manipulate JSON files - documentation gnupg2 to sign, encrypt and verify files - documentation python3 to write and execute Python programs - documentation `}).add({id:19,href:"/docs/prologue/quick-start/",title:"Quick Start",description:`PiRogue # Build your PiRogue →
Alternatively, you can buy a PiRogue from us by reaching out to us.
Colander # In development`,content:`PiRogue # Build your PiRogue →
Alternatively, you can buy a PiRogue from us by reaching out to us.
Colander # In development
`}).add({id:20,href:"/docs/colander/overview/",title:"Overview",description:`Colander web platform is a case and incident response management platform that integrates seamlessly with the hardware and software components. Colander provides a centralized hub for managing investigations, streamlining workflows, and enabling effective collaboration among team members.
Knowledge management: Colander facilitates the organization and sharing of investigative knowledge, ensuring that insights are readily available to team members, promoting collaboration and efficiency.
Artifact management: Colander streamlines the handling and preservation of digital evidence, maintaining chain of custody and ensuring admissibility in legal proceedings.`,content:`Colander web platform is a case and incident response management platform that integrates seamlessly with the hardware and software components. Colander provides a centralized hub for managing investigations, streamlining workflows, and enabling effective collaboration among team members.
Knowledge management: Colander facilitates the organization and sharing of investigative knowledge, ensuring that insights are readily available to team members, promoting collaboration and efficiency.
Artifact management: Colander streamlines the handling and preservation of digital evidence, maintaining chain of custody and ensuring admissibility in legal proceedings.
Digital investigation: Colander simplifies the digital investigation process, offering a central platform for case management, evidence handling, gathering threat intelligence for 3rd-party, collaboration, and network traffic analysis.
Key features # Organize knowledge in different cases Invite team member to collaborate to your cases Represent the real world with generic entities such as artifact, actor, observable, event and more Graph knowledge using the web graph editor Write documentation at anytime Import intelligence from 3rd-party service such as VirusTotal or OTX Alien Vault via Threatr Collect and sign artifacts directly from your PiRogue Analyze decrypted network traffic and payloads Decode network payload with CyberChef Apply Yara rules directly on the network traffic Ensure artifact integrity and authenticity Generate comprehensive data transmission report Create feeds to export your findings in different formats `}).add({id:21,href:"/docs/colander/architecture/",title:"Architecture",description:`Colander relies on different services:
colander-postgres: Postgres database colander-front: Gunicorn serving the pages of Colander colander-worker: Django Q2 cluster of workers traefik: Traefik reverse proxy ensuring TLS termination and routing cyberchef: CyberChef instance playwright: service using Playwright to take URL screenshot and capture the HAR elasticsearch: single node ElasticSearch server storing network traffic analysis minio: Minio S3-compatible object storage to store artifacts redis: Redis server ensuring the communication between the front and the workers for both Colander and Threatr watchtower: Watchtower service keeping the stack up to date Colander comes with Threatr which relies on:`,content:`Colander relies on different services:
colander-postgres: Postgres database colander-front: Gunicorn serving the pages of Colander colander-worker: Django Q2 cluster of workers traefik: Traefik reverse proxy ensuring TLS termination and routing cyberchef: CyberChef instance playwright: service using Playwright to take URL screenshot and capture the HAR elasticsearch: single node ElasticSearch server storing network traffic analysis minio: Minio S3-compatible object storage to store artifacts redis: Redis server ensuring the communication between the front and the workers for both Colander and Threatr watchtower: Watchtower service keeping the stack up to date Colander comes with Threatr which relies on:
threatr-postgres: Postgres database threatr-front: Gunicorn serving the pages of Threatr threatr-worker: Django Q2 cluster of workers `}).add({id:22,href:"/docs/colander/deployment/",title:"Deployment",description:`Colander official Docker image is available on GitHub. The stack we provide comes with the service Watchtower that will automatically update the version of Colander you deployed.
Requirements # We suggest to use a dedicated server with at least:
4 cores 4GB of RAM 500GB of storage space We recommend to install Debian as is the operating system we know, and we will be able to guide you through all different steps for installation, maintenance and debugging.`,content:`Colander official Docker image is available on GitHub. The stack we provide comes with the service Watchtower that will automatically update the version of Colander you deployed.
Requirements # We suggest to use a dedicated server with at least:
4 cores 4GB of RAM 500GB of storage space We recommend to install Debian as is the operating system we know, and we will be able to guide you through all different steps for installation, maintenance and debugging.
Your server must have a public IP address as well as a domain name.
Deployment procedure # Once your server is up and running, download the latest Colander deployment package available on GitHub and decompress it on your server.
Configuration # The next step is to configure the stack to be deployed. To do so, edit the file .envs/.tpl/.base and set the following variables according to your production environment:
ACME_EMAIL: the email address attached to the TLS certificate ADMIN_NAME: full name of the administrator ADMIN_EMAIL: email address that will receive notifications on crashes and unhandled errors ROOT_DOMAIN: the domain name pointing to your server DJANGO_DEFAULT_FROM_EMAIL: the email address used for sending emails EMAIL_HOST: the host to use for sending email (can be the SMTP server of your email provider) EMAIL_HOST_USER: the username to use for the SMTP server EMAIL_HOST_PASSWORD: the password to use for the SMTP server EMAIL_PORT: the port to use for the SMTP server EMAIL_USE_TLS: True if the SMTP server uses TLS, False otherwise EMAIL_USE_SSL: True if the SMTP server uses SSL, False otherwise Find more details about the email configuration in the Django documentation.
Once configured, you have to generate the entire configuration of the stack by running the following command:
bash gen.sh The script will generate multiple files containing environment variables that will be passed to the different services.
First boot # Now, you are ready to fire up the stack using docker compose:
docker compose -f no-sso.yml build docker compose -f no-sso.yml up -d The Colander stack is now starting, you can see the logs by running
docker compose -f no-sso.yml logs Check with your web browser if Colander is up by browsing the domain name you configured.
Admin user # Next, you have to create an admin user for both Colander and Threatr by running
docker compose -f no-sso.yml run --rm colander-front python manage.py createsuperuser docker compose -f no-sso.yml run --rm threatr-front python manage.py createsuperuser and follow the instructions.
Don\u0026rsquo;t forget to save the credentials in your favorite password manager!
Note that the administration panels are accessible at random URLs specified in the files .envs/.production/.colander and .envs/.production/.threatr.
👉 Don\u0026rsquo;t forget to backup the .envs folder. Insert default data # Threatr comes with a set of predefined entity types, to load them, run the following command
docker compose -f no-sso.yml run --rm threatr-front python manage.py insert_default_data Connect Colander to Threatr # In the administration panel of Threatr, create a regular user via the Users menu. Then, via the Auth Token menu, create a new API key for the user you just created. Next, via the menu Vendor credentials, create a new entry for each 3rd-party API key you have for Virus Total and/or OTX Alien Vault.
for VirusTotal, use the vendor identifier vt and for the credentials field, set {\u0026#34;api_key\u0026#34;: \u0026#34;your VT API key\u0026#34;} for OTX Alien Vault, use the vendor identifier otx and for the credentials field, set {\u0026#34;api_key\u0026#34;: \u0026#34;your OTX API key\u0026#34;} NB you can add multiple API keys for a same vendor
In the administration panel of Colander, via the menu Backend credentials, create a new entry with threatr as backend identifier and for the credentials field, set
{\u0026#34;api_key\u0026#34;: \u0026#34;your Threatr API key\u0026#34;} Development environment # Setup # The development environment relies on Docker Compose (or Podman). The file local.yml provides the entire stack you need.
git clone https://github.com/PiRogueToolSuite/colander.git cd colander docker compose -f local.yml build docker compose -f local.yml up -d docker compose -f local.yml run --rm django python manage.py createsuperuser docker compose -f local.yml logs -f -n 44 django # to check the logs Then, you should be able to browse and log-in Colander at http://localhost:8000.
To stop your Colander stack:
docker compose -f local.yml stop `}).add({id:23,href:"/docs/colander/graphical-interface/",title:"Graphical interface",description:`The graphical interface of Colander allows to navigate through the different workspaces as well as easily switching from one case to another or quickly searching for entities within a selected case or within all the user’s cases.
The graphical interface changes depending on a case as been selected or not. When no case is selected, the quick search bar will apply to all the cases the user has access to. In this mode, only 2 workspaces are accessible:`,content:`The graphical interface of Colander allows to navigate through the different workspaces as well as easily switching from one case to another or quickly searching for entities within a selected case or within all the user’s cases.
The graphical interface changes depending on a case as been selected or not. When no case is selected, the quick search bar will apply to all the cases the user has access to. In this mode, only 2 workspaces are accessible:
Cases to create or edit cases Collaborate to create or edit teams Overview of the Colander interface when no case is selected When a case is selected, the quick search bar only applies to the current case. In this mode, 6 workspaces are accessible:
Collect to create, edit, delete entities Graph to open the graph editor Document to open the documentation Markdown editor Feeds to create, edit or delete export feeds Investigate to quickly retrieve intelligence from VirusTotal or OTX Alien Vault via Threatr CyberChef to open to self-hosted CyberChef tool Overview of the Colander interface when a case is selected When a case is selected, the documentation editor can be opened within the current workspace. The documentation editor is then shown on the lower third of the page.
Overview of the Colander graph and documentation editor `}).add({id:24,href:"/docs/colander/account-administration/",title:"Account administration",description:`Administrator account # Once Colander is deployed and running, the system administrator has to create a first account with administrative rights for both Colander and Threatr. To do so, the system administrator has to run the following command on the server running Colander:
docker compose -f no-sso.yml run --rm colander-front python manage.py createsuperuser docker compose -f no-sso.yml run --rm threatr-front python manage.py createsuperuser Those credentials have to be securely stored and must not be shared.`,content:`Administrator account # Once Colander is deployed and running, the system administrator has to create a first account with administrative rights for both Colander and Threatr. To do so, the system administrator has to run the following command on the server running Colander:
docker compose -f no-sso.yml run --rm colander-front python manage.py createsuperuser docker compose -f no-sso.yml run --rm threatr-front python manage.py createsuperuser Those credentials have to be securely stored and must not be shared.
This first administrator account is necessary to create others accounts.
Administration panel # Administrators can use the administration panel of Colander which is located at a random location. This location is defined in 2 separate files:
.envs/.production/.colander, the variable DJANGO_ADMIN_URL defines the location of the administration panel of Colander .envs/.production/.threatr, the variable DJANGO_ADMIN_URL defines the location of the administration panel of Threatr The administration panel of Colander is accessible at https://[colander domain]/[DJANGO_ADMIN_URL] and https://[threatr domain]/[DJANGO_ADMIN_URL] for Threatr.
User accounts # Account creation # By now, the only way for a new user to get an account is requesting its creation to an administrator. The administrator must use the administration panel to add a new user.
Menu of the administration panel showing the entry for managing the accounts Then, the administrator has to specify the username and password that will then be shared with the user.
Menu of the administration panel showing the user account creation form To grant the administrative rights to a specific user, an administrator has to select Active, Staff status and Superuser status options.
Menu of the administration panel showing the options to grant administrative rights Instead of deleting an account, administrators can deactivate a given account.
👉 Raw passwords are not stored, so there is no way to see the user’s password. Account verification # At their first login, a user has to set a primary email address by opening their profile (click on the username at the top right of Colander then Manage in the email address section) and has to go through the verification process.
Having a verified primary email address linked is necessary to reset the password of the account.
Password change # After having linked their email address, the user can logout, go back to the login page and click on Forgot your password?. An email detailing the procedure will be sent to the primary email address linked to the account.
2-factor authentication # Users can set up 2-factor authentication by following the procedure in their profile, section 2FA. By now, Colander only supports TOTP.
Overview of the form for setting up the 2-factor authentication `}).add({id:25,href:"/docs/colander/collaboration/",title:"Collaboration",description:`Teams # Teams in Colander are the only way to share cases with other users. To create a team, go in Colander \u0026gt; Collaborate \u0026gt; Teams and give a name.
Team creation form Once created, click on Details to add a contributor. Since a Colander instance can host multiple users from different organizations, users cannot search for another user by their name. Instead, the owner of the team has to ask other users for their Contributor ID.`,content:`Teams # Teams in Colander are the only way to share cases with other users. To create a team, go in Colander \u0026gt; Collaborate \u0026gt; Teams and give a name.
Team creation form Once created, click on Details to add a contributor. Since a Colander instance can host multiple users from different organizations, users cannot search for another user by their name. Instead, the owner of the team has to ask other users for their Contributor ID. This way, they are free to decide whether they want to share their ID or not. The Contributor ID can be found in user\u0026rsquo;s profile.
Overview of the form for adding a contributor to a team 👉 Only the owner of the team can:
edit the team delete the team add or remove contributors Share a case # Only the owner of a case can share it with a team they are either owner or contributor. To share a case with one or multiple teams, simply edit the case and select/deselect the teams you want to share the case with.
Form allowing to share a case with one or many teams `}).add({id:26,href:"/docs/colander/case-management/",title:"Case management",description:`In the context of digital investigation, the effective organization and management of cases are imperative. As a digital investigator you focus on documenting incident, the utilization of Colander serves as a comprehensive platform to streamline and document investigative efforts. This document explain how to use Colander for organizing and managing digital investigation cases.
Case management # Case management is the overarching framework that organizes and oversees the entire digital investigation process, from the initial identification of a potential crime or incident to the final report and resolution.`,content:`In the context of digital investigation, the effective organization and management of cases are imperative. As a digital investigator you focus on documenting incident, the utilization of Colander serves as a comprehensive platform to streamline and document investigative efforts. This document explain how to use Colander for organizing and managing digital investigation cases.
Case management # Case management is the overarching framework that organizes and oversees the entire digital investigation process, from the initial identification of a potential crime or incident to the final report and resolution. It serves as a central hub for coordinating all aspects of the investigation, ensuring that the investigation is conducted effectively and efficiently.
Case folders # Comprehensive and well-structured case files serve as the backbone of any digital investigation. They should contain detailed information about the investigation, including the nature of the incident, relevant case documents, witness statements, electronic evidence, and any other relevant data. In Colander, everything is organized in cases. A case is defined by a name, a description and its confidentiality TLP and PAP levels.
Overview of the case creation form Timeline/Chronology # Establishing a clear and accurate timeline of events is crucial for understanding the sequence of actions taken and identifying potential patterns or relationships. This timeline should be built from various sources of information, including witness statements, electronic evidence, and communication logs. Among other types of entities, Colander allows describing events of different types. These events are then organized in a timeline. These events can be related to actions performed on the current they belong to or can be related to any other entities.
Overview of the event timeline Collaboration # Effective communication and collaboration are essential for ensuring that all parties involved in the investigation are aware of the latest developments, progress is tracked, and potential roadblocks or issues can be promptly addressed. This includes sharing relevant information across departments, and facilitating communication between investigators, legal teams, and other stakeholders. In Colander, cases, and their entire content, can be shared with multiple teams of contributors. Only the owner of a team can invite new collaborators, to do so, the owner has to ask each user their contributor ID. This way, users can refuse being added to a given team.
Overview of team management `}).add({id:27,href:"/docs/colander/knowledge-management/",title:"Knowledge management",description:`Knowledge management is an ongoing process of capturing, organizing, and sharing the knowledge and expertise gained from digital investigations. It aims to create a repository of best practices, guidelines, and case studies that can be leveraged by future investigators to improve their investigative techniques and decision-making processes.
Knowledge repository # A central knowledge repository serves as the storage and organization hub for digital evidence, case files, investigative techniques, and lessons learned from past investigations.`,content:`Knowledge management is an ongoing process of capturing, organizing, and sharing the knowledge and expertise gained from digital investigations. It aims to create a repository of best practices, guidelines, and case studies that can be leveraged by future investigators to improve their investigative techniques and decision-making processes.
Knowledge repository # A central knowledge repository serves as the storage and organization hub for digital evidence, case files, investigative techniques, and lessons learned from past investigations. This repository allows investigators to quickly access relevant information, share knowledge with colleagues, and track the evolution of investigative practices.
Overview of different entities saved in Colander Knowledge sharing # Facilitating the exchange of knowledge among investigators, both within the same organization and across different jurisdictions, is crucial for promoting learning and continuous improvement. This can be achieved through formal knowledge sharing feeds. Colander supports export feeds accessible via a password-protected URL giving access to the knowledge in different formats such as JSON, STIX 2 or CSV.
Overview of a feed exporting entities Knowledge codification # Knowledge can be represented in a way that is both understandable and usable by a wide range of people, regardless of their technical expertise. This is important for digital investigations, as it allows investigators to share knowledge with each other, even if they have different levels of technical knowledge. Colander uses standard and generic terminology and concepts. This helps to ensure that everyone is using the same language to describe the same things.
Colander defines the following types of entity:
Actors: Individuals or groups that can perform actions in the digital environment. Artifacts: Digital traces left behind by actors or the execution of software. Devices: Computers, smartphones, tablets, and other electronic devices that store and transmit data. Detection rules: Sets of criteria used to identify suspicious activity or potential threats. Threats: Potential risks or harmful actions that can target individuals, organizations, or systems. Observables: Specific pieces of evidence or information that can be used to identify a technical information. Events: Recorded occurrences of actions or changes in a system. Fragments of data: Small pieces of data that can be used to reconstruct a larger dataset or provide insights into the activities of actors or systems. Each type of entity can be more precisely defined. For example, Colander comes with a set of sub-types such as Observable / IP v4, Artifact / Android backup, etc.
Example of entity sub-types Colander defines two different types of relationships: loose and tight. Tight relationships are defined as attributes attached to an entity following a pre-defined ontology, they are not editable with the graph editor and are marked with a padlock. Loose relationships are any user-defined relationships.
Colander supports the following tight relationships which represents the bare minimum level of information needed to represent relationships between entities:
Artifact has been extracted from a Device Device is operated by an Actor Observable has been extracted from an Artifact Observable indicates a Threat Observable is operated by an Actor Event has been observed on a Device Event has been detected by a Detection rule Event has been been extracted from an Artifact Event involves a set of Observable Fragment of data has been extracted from an Artifact The users are free to follow Colander’s ontology or to use their own.
`}).add({id:28,href:"/docs/colander/knowledge-graph/",title:"Knowledge graph",description:`In the realm of digital investigations, where the volume and complexity of data can be overwhelming, knowledge graphs emerge as a sophisticated tool for organizing, analyzing, and extracting meaningful insights. These structured representations of knowledge, akin to semantic networks, connect entities and their interrelationships, providing a cohesive framework for comprehending the intricacies of digital environments.
At the heart of knowledge graphs lies a network of interconnected nodes, each representing a distinct entity.`,content:`In the realm of digital investigations, where the volume and complexity of data can be overwhelming, knowledge graphs emerge as a sophisticated tool for organizing, analyzing, and extracting meaningful insights. These structured representations of knowledge, akin to semantic networks, connect entities and their interrelationships, providing a cohesive framework for comprehending the intricacies of digital environments.
At the heart of knowledge graphs lies a network of interconnected nodes, each representing a distinct entity. These entities encompass a broad spectrum of real-world elements, encompassing actors (individuals or groups capable of actions), artifacts (digital traces left by actors or software), devices (ranging from computers and smartphones to IoT devices), detection rules (sets of criteria identifying suspicious activity), threats (potential risks or harmful actions), observables (evidence or information aiding threat identification), events (recorded occurrences of system changes), and fragments of data (pieces contributing to larger datasets).
The relationships between these entities, represented as edges within the knowledge graph, capture the intricate web of connections that underpin digital investigations. These relationships can be established based on various factors, such as \u0026ldquo;extracted from\u0026rdquo; \u0026ldquo;detected by,\u0026rdquo; \u0026ldquo;associated with,\u0026rdquo; or \u0026ldquo;related to.\u0026rdquo;
By virtue of their graph-based representation, knowledge graphs offer a multitude of benefits for digital investigations, enabling investigators to:
Identify relationships between actors: Uncover connections between individuals or groups involved in the investigation, such as communication patterns, file access permissions, or device usage, aiding in identifying collusion or malicious activities. Track artifact movement: Trace the path of digital artifacts, such as files or emails, across systems and networks, facilitating the identification of their origin and final destination. Leverage contextual understanding of observables: Gain insights into the significance of observables, such as IP addresses or malware signatures, by analyzing their associated entities and relationships, aiding in determining their relevance to known threats. Infer missing data: Utilize the relationships between known entities to extrapolate missing information, filling in gaps in evidence or predicting future events based on existing patterns. Knowledge graphs serve as a powerful tool for digital investigators, enabling them to navigate the complexities of vast datasets and extract meaningful insights. Their ability to represent relationships between entities, track artifact movement, contextualize observables, and infer missing data proves invaluable in solving digital investigations and mitigating cyber threats.
Overview the graph editor The graph editor of Colander allows the users to quickly add, edit, remove entities and relationships, and layout the graph in the way they want.
Graph editor actions # mouse wheel: zoom in and out click + drag on the background: move the whole graph double click on the background: open the quick search side panel double click on an entity: open the entity overview side panel right click on the background: open the graph menu to quickly create a new entity right click on an entity: open the entity menu to create a new relation open the entity overview quickly edit the entity select the connected component layout the neighbors right click on a relation: open the relation menu to rename the relation delete the relation select the connected component ctrl + click on entities: select multiple entities ctrl + click + drag: area selection click + drag on selected entities: move the selected entities click on the background: empty the selection The padlock prefixing the name of a link between 2 entities indicates that this relation has been inferred from the details specified at the creation of one of the 2 related entities. For example, if we created an observable and specified that it has been extracted from a specific artifact, the relationship between the 2 entities cannot be changed in the graph preventing losing an important information.
`}).add({id:29,href:"/docs/colander/external-sources/",title:"🚧 External sources",description:"",content:""}).add({id:30,href:"/docs/colander/artifact-management/",title:"🚧 Artifact management",description:"",content:""}).add({id:31,href:"/docs/colander/chain-of-custody/",title:"Chain of custody",description:`In the intricate domain of digital forensics, maintaining confidentiality is paramount to protect sensitive information and ensure the integrity of investigations. Two widely adopted confidentiality frameworks, Traffic Light Protocol (TLP) and Permissible Actions Protocol (PAP), provide structured guidelines for sharing and restricting access to sensitive data. These frameworks empower digital forensic practitioners to navigate the delicate balance between information sharing and confidentiality.
TLP \u0026amp; PAP # The Traffic Light Protocol (TLP) employs a color-coded system to classify information and guide its dissemination:`,content:`In the intricate domain of digital forensics, maintaining confidentiality is paramount to protect sensitive information and ensure the integrity of investigations. Two widely adopted confidentiality frameworks, Traffic Light Protocol (TLP) and Permissible Actions Protocol (PAP), provide structured guidelines for sharing and restricting access to sensitive data. These frameworks empower digital forensic practitioners to navigate the delicate balance between information sharing and confidentiality.
TLP \u0026amp; PAP # The Traffic Light Protocol (TLP) employs a color-coded system to classify information and guide its dissemination:
TLP:RED: Information is highly sensitive and should only be shared with authorized individuals on a limited basis, safeguarding highly confidential or classified data. TLP:AMBER: Information is restricted to specific individuals or organizations with a need-to-know basis, ensuring targeted sharing for specific purposes. TLP:GREEN: Information can be shared within a defined community, such as law enforcement or industry partners, enabling collaboration within trusted circles. TLP:CLEAR: Information can be shared openly without limitations, facilitating widespread dissemination. Permissible Actions Protocol (PAP) focuses on restricting access to specific individuals, providing a more granular approach to confidentiality:
PAP:RED: Non-detectable actions only. Recipients may not use PAP:RED information on the network. Only passive actions on logs, that are not detectable from the outside. PAP:AMBER: Recipients may use PAP:AMBER information for conducting online checks, like using services provided by third parties (e.g. VirusTotal), or set up a monitoring honeypot. PAP:GREEN: Active actions. Recipients may use PAP:GREEN information to ping the target, block incoming/outgoing traffic from/to the target or specifically configure honeypots to interact with the target. PAP:CLEAR: Open, no restrictions The application of TLP and PAP frameworks varies depending on the nature of the information and the context of the investigation. TLP is often used in sharing threat intelligence, incident reports, or vulnerability information, while PAP is typically applied to specific documents, files, or datasets that require restricted access.
The benefits of employing TLP and PAP frameworks include:
Protection of sensitive information: These frameworks prevent unauthorized disclosure of confidential data, ensuring that sensitive information remains protected from unauthorized access or leaks. Facilitated information sharing: They enable controlled dissemination of information among authorized parties, allowing for effective collaboration and sharing of knowledge while maintaining confidentiality. Enhanced collaboration: By providing a common language and understanding for managing sensitive data, TLP and PAP promote effective collaboration among different stakeholders involved in investigations. Maintained trust and integrity: The use of these frameworks upholds the trust and integrity of investigations and information sharing, ensuring that sensitive data is handled responsibly and with due diligence. Traffic Light Protocol (TLP) and Permissible Actions Protocol (PAP) serve as essential tools for digital forensic practitioners, enabling them to effectively protect sensitive data while fostering collaboration and ensuring the integrity of investigations. By employing these frameworks, they can navigate the delicate balance between information sharing and confidentiality, ensuring that sensitive information is disseminated appropriately and securely.
Artifact integrity # In addition to the 2 frameworks listed above, it is crucial to implement mechanisms ensuring digital artifact/evidence integrity and proving their origin that are crucial in maintaining the authenticity and trustworthiness of digital information. SHA-256 file hash, detached RSA signature, and the signer\u0026rsquo;s public key are fundamental tools employed to achieve this goal.
SHA-256 file hash # SHA-256 (Secure Hash Algorithm 256) is a cryptographic hash function that generates a unique fingerprint or hash value for a given digital file. This hash value serves as a reliable identifier for the file\u0026rsquo;s content, ensuring that any modifications to the file will result in a different hash value.
Detached RSA signature # A detached RSA signature is a cryptographic signature that is created separately from the original file. The signer uses their private RSA key to encrypt a hash value of the file, generating a signature file. The signature file can then be attached to the original file or stored separately.
Signer\u0026rsquo;s Public Key # The signer\u0026rsquo;s public key is a component of the RSA key pair that is used to verify the detached RSA signature. Anyone can obtain and use the public key to decrypt the signature file, revealing the original hash value.
Artifact integrity verification # To verify the integrity and origin of a digital file using SHA-256 file hash, detached RSA signature, and the signer\u0026rsquo;s public key, follow these steps:
Compute the SHA-256 hash value of the original file. This can be done using various tools or libraries available for different platforms.
Verify the detached RSA signature using the signer\u0026rsquo;s public key. Decrypt the signature file using the signer\u0026rsquo;s public key, revealing the hash value embedded within.
Compare the computed hash value with the hash value extracted from the detached RSA signature. If the two hash values match, it confirms that the file has not been tampered with since it was signed.
Using a detached RSA signature offers several advantages:
Independent verification: The signature can be verified independently without the original file, allowing for easier verification and storage.
Integrity protection: The signature protects the hash value, ensuring that any modifications to the file will invalidate the signature and reveal tampering.
Long-term integrity: The signature can be used to verify the file\u0026rsquo;s integrity even if the original file is lost or corrupted.
Utilizing SHA-256 file hash, detached RSA signature, and the signer\u0026rsquo;s public key provides a robust and reliable method for ensuring digital evidence integrity and proving its origin. These techniques are widely used in various fields, including forensics, legal investigations, and software distribution, to safeguard the authenticity and trustworthiness of digital information.
`}).add({id:32,href:"/docs/colander/network-traffic-decryption/",title:"Network traffic decryption",description:"Have a look to the guide dedicated to network traffic decryption →",content:`Have a look to the guide dedicated to network traffic decryption →
`}).add({id:33,href:"/docs/recipes/",title:"Recipes",description:"Recipes",content:""}).add({id:34,href:"/docs/colander/network-traffic-analysis/",title:"Network traffic analysis",description:"Have a look to the guide dedicated to network traffic decryption →",content:`Have a look to the guide dedicated to network traffic decryption →
`}).add({id:35,href:"/docs/colander/write-documentation/",title:"🚧 Write documentation",description:"",content:""}).add({id:36,href:"/docs/colander/rest-api/",title:"REST API",description:`Colander # A Python 3 library abstracting the REST API of Colander is available on GitHub.
To use it, you have to specify your Colander API you can find in your profile.
Installation
pip install colander-client Basic usage
from colander_client.client import Client base_url = \u0026#39;https://my-colander-server\u0026#39; api_key = \u0026#39;my-user-api-key\u0026#39; client = Client(base_url=base_url, api_key=api_key) # Assuming the given case id: case_id = \u0026#39;current-case-id-im-working-on\u0026#39; case = client.get_case(case_id) client.switch_case(case) def progress(what, percent, status): print(f\u0026#34;{what} is at {percent}%, currently it is: {status}\u0026#34;) # in case of artifact upload progress \u0026#39;what\u0026#39; is the given filepath a_type = client.`,content:`Colander # A Python 3 library abstracting the REST API of Colander is available on GitHub.
To use it, you have to specify your Colander API you can find in your profile.
Installation
pip install colander-client Basic usage
from colander_client.client import Client base_url = \u0026#39;https://my-colander-server\u0026#39; api_key = \u0026#39;my-user-api-key\u0026#39; client = Client(base_url=base_url, api_key=api_key) # Assuming the given case id: case_id = \u0026#39;current-case-id-im-working-on\u0026#39; case = client.get_case(case_id) client.switch_case(case) def progress(what, percent, status): print(f\u0026#34;{what} is at {percent}%, currently it is: {status}\u0026#34;) # in case of artifact upload progress \u0026#39;what\u0026#39; is the given filepath a_type = client.get_artifact_type_by_short_name( \u0026#39;SAMPLE\u0026#39; ) # Assuming we have switched to a Case artifact = client.upload_artifact(filepath=\u0026#39;/tmp/captured.file\u0026#39;, artifact_type=a_type, progress_callback=progress) Find more details on GitHub.
Threatr # Threatr is a bridge between Colander and various 3rd-party services such as VirusTotal and OTX Alien Vault. Even if it is designed to operate along with Colander, Threatr can be used standalone and users can interact with it via its REST API.
By now, Threatr supports requests on the following types of observables:
IPV4 IPV6 DOMAIN MD5 SHA1 SHA256 And can return various types of information such as threats, VirusTotal detection score or reports.
Threatr propagates user\u0026rsquo;s requests to the different configured 3rd-parties and returns the aggregated entities along with the knowledge graph linking the different found entities with the requested one. Threatr stores the results in its internal database and will always return the data already stored unless the attribute force is set to true. By forcing the refresh of the data, Threatr will propagate the user\u0026rsquo;s request to all the different 3rd-party configured.
The retrieval of the data from the 3rd-party is done asynchronously. Thus, it is necessary to replay the same request until the status is no longer ENQUEUED.
👉 Do not forget to reset the attribute force to false or Threatr will be constantly requesting the same information to the 3rd-party. Once Threatr has retrieved all the information from the different 3rd-party, it will return a JSON document following this structure:
root_entity: the requested entity entities: the list of all retrieved entities (DNS records, etc.) events: the list of all retrieved events (Passive DNS, etc.) relations: the knowledge graph linking the entities all together, root_entity included graph: the Mermaid definition of the knowledge graph Users can ask Threatr for threat intelligence by sending POST HTTP requests. In the following example, we ask Threatr to get threat intelligence about a given SHA256 observable.
curl -X POST --location \u0026#34;[threat URL]\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -H \u0026#34;Authorization: Token [api-key]\u0026#34; \\ -d \u0026#34;{\\\u0026#34;super_type\\\u0026#34;: \\\u0026#34;observable\\\u0026#34;, \\\u0026#34;type\\\u0026#34;: \\\u0026#34;sha256\\\u0026#34;, \\ # we provide a SHA256 observable \\\u0026#34;value\\\u0026#34;: \\\u0026#34;854774a198db490a1ae9f06d5da5fe6a1f683bf3d7186e56776516f982d41ad3\\\u0026#34;, \\ # the SHA256 \\\u0026#34;force\\\u0026#34;: false}\u0026#34; It returns a document JSON looking like:
{ \u0026#34;root_entity\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;7c208f04-54f6-441c-8823-a125ee8d9151\u0026#34;, \u0026#34;super_type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Observable\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;OBSERVABLE\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: null }, \u0026#34;type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;SHA256\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;SHA256\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: \u0026#34;nf-fa-hashtag\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;854774a198db490a1ae9f06d5da5fe6a1f683bf3d7186e56776516f982d41ad3\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;source_url\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-18T20:36:38.377497Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-03-20T15:06:31.046058Z\u0026#34;, \u0026#34;tlp\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;pap\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;md5\u0026#34;: \u0026#34;79ba96848428337e685e10b06ccc1c89\u0026#34;, \u0026#34;sha1\u0026#34;: \u0026#34;51b31827c1d961ced142a3c5f3efa2b389f9c5ad\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;3007920\u0026#34;, \u0026#34;tlsh\u0026#34;: \u0026#34;T18AD5338F15B14C4A94A719F7A1B6F2480D6D6BE1740C6342A32C6107B9D2F31AF6FC9B\u0026#34;, \u0026#34;vhash\u0026#34;: \u0026#34;32b92707c2fd75aba00c39dde6dc91f9\u0026#34;, \u0026#34;sha256\u0026#34;: \u0026#34;854774a198db490a1ae9f06d5da5fe6a1f683bf3d7186e56776516f982d41ad3\u0026#34;, \u0026#34;ssdeep\u0026#34;: \u0026#34;49152:rlaYuMuLPV74she6ZMKqvoWY9KqUoHLUfgP8csv5oJewBktwFcBVOhOUfFW:r0YhiqshtJqQWY9GEUoP8zv5f0kuFczJ\u0026#34;, \u0026#34;filesize\u0026#34;: \u0026#34;3007920\u0026#34;, \u0026#34;vt_score\u0026#34;: \u0026#34;39/76\u0026#34;, \u0026#34;file_type\u0026#34;: \u0026#34;Zip archive data, at least v2.0 to extract\u0026#34;, \u0026#34;ZIP:ZipCRC\u0026#34;: \u0026#34;0x2eb041f1\u0026#34;, \u0026#34;file_class\u0026#34;: \u0026#34;APK\u0026#34;, \u0026#34;is_malicious\u0026#34;: \u0026#34;True\u0026#34;, \u0026#34;source_vendor\u0026#34;: \u0026#34;OTX Alien Vault\u0026#34;, \u0026#34;ZIP:ZipBitFlag\u0026#34;: \u0026#34;0x0808\u0026#34;, \u0026#34;ZIP:ZipFileName\u0026#34;: \u0026#34;META-INF/MANIFEST.MF\u0026#34;, \u0026#34;ZIP:ZipModifyDate\u0026#34;: \u0026#34;2019:10:23 10:54:58\u0026#34;, \u0026#34;ZIP:ZipCompression\u0026#34;: \u0026#34;Deflated\u0026#34;, \u0026#34;ZIP:ZipCompressedSize\u0026#34;: \u0026#34;505\u0026#34;, \u0026#34;ZIP:ZipRequiredVersion\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;ZIP:ZipUncompressedSize\u0026#34;: \u0026#34;956\u0026#34; } }, \u0026#34;entities\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;01ee1c48-8670-4535-b90f-b99070fd02e4\u0026#34;, \u0026#34;super_type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;External documentation\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;EXT_DOC\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: null }, \u0026#34;type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Analysis report\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;REPORT\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: \u0026#34;nf-fa-file-lines\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;FinSpy spyware found in Egypt, and Mac and Linux versions revealed\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\\\u0026#34;FinSpy is a commercial spyware suite produced by the Munich-based company FinFisher Gmbh. Since 2011 researchers have documented numerous cases of targeting of Human Rights Defenders (HRDs) - including activists, journalists, and dissidents with the use of FinSpy in many countries, including Bahrain, Ethiopia, UAE, and more.\\\u0026#34;\u0026#34;, \u0026#34;source_url\u0026#34;: \u0026#34;https://www.amnesty.org/en/latest/research/2020/09/german-made-finspy-spyware-found-in-egypt-and-mac-and-linux-versions-revealed/\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-18T20:36:40.807646Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-03-20T15:06:31.012557Z\u0026#34;, \u0026#34;tlp\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;pap\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;tags\u0026#34;: \u0026#34;linux,osx,finspy,android,backdoor,cobalt strike,spyware\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;2020-09-25 18:20:44.470000+00:00\u0026#34;, \u0026#34;modified\u0026#34;: \u0026#34;2020-10-25 00:02:49.937000+00:00\u0026#34;, \u0026#34;source_vendor\u0026#34;: \u0026#34;OTX Alien Vault\u0026#34; } }, { \u0026#34;id\u0026#34;: \u0026#34;be2a862c-30d6-468f-91c0-583c00286f83\u0026#34;, \u0026#34;super_type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Threat\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;THREAT\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: null }, \u0026#34;type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Trojan\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;TROJAN\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: \u0026#34;nf-fa-bug\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;trojan.finspy/techfu\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;source_url\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-20T11:52:05.535519Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-03-20T15:06:27.658068Z\u0026#34;, \u0026#34;tlp\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;pap\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;tags\u0026#34;: \u0026#34;apk,checks-gps,sudo,android,contains-elf\u0026#34;, \u0026#34;source_vendor\u0026#34;: \u0026#34;VirusTotal\u0026#34; } }, { \u0026#34;id\u0026#34;: \u0026#34;bbc19a6b-8b56-4efd-96d5-c56bb1128d59\u0026#34;, \u0026#34;super_type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;External documentation\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;EXT_DOC\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: null }, \u0026#34;type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Analysis report\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;REPORT\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: \u0026#34;nf-fa-file-lines\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;German-made FinSpy spyware found in Egypt, and Mac and Linux versions revealed\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;source_url\u0026#34;: \u0026#34;https://github.com/AmnestyTech/investigations/blob/master/2020-09-25_finfisher/android_tlv_list.csv\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-18T20:36:40.825174Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-03-20T15:06:31.025317Z\u0026#34;, \u0026#34;tlp\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;pap\u0026#34;: \u0026#34;WHITE\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;tags\u0026#34;: \u0026#34;android finspy,backdoored,older linux,macos installer,linux finspy,older mac os\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;2020-09-25 16:28:05.448000+00:00\u0026#34;, \u0026#34;modified\u0026#34;: \u0026#34;2020-10-25 00:02:49.937000+00:00\u0026#34;, \u0026#34;source_vendor\u0026#34;: \u0026#34;OTX Alien Vault\u0026#34; } } ], \u0026#34;events\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;ba3180c7-6bb0-46c0-8d2b-ac2b853dec9c\u0026#34;, \u0026#34;type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;AntiVirus detection\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;AV_DETECTION\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: \u0026#34;nf-oct-alert\u0026#34; }, \u0026#34;first_seen\u0026#34;: \u0026#34;2022-11-23T13:30:52Z\u0026#34;, \u0026#34;last_seen\u0026#34;: \u0026#34;2022-11-23T13:30:52Z\u0026#34;, \u0026#34;count\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Latest analysis on VT\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-20T15:58:23.694985Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-03-20T15:58:23.704958Z\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;attributes\u0026#34;: { \u0026#34;source_vendor\u0026#34;: \u0026#34;VirusTotal\u0026#34; }, \u0026#34;involved_entity\u0026#34;: \u0026#34;7c208f04-54f6-441c-8823-a125ee8d9151\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;ba7e49bb-bf7b-4c00-a9c9-0eced24890e2\u0026#34;, \u0026#34;type\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Hit\u0026#34;, \u0026#34;short_name\u0026#34;: \u0026#34;HIT\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;nf_icon\u0026#34;: \u0026#34;nf-mdi-white_balance_sunny\u0026#34; }, \u0026#34;first_seen\u0026#34;: \u0026#34;2019-11-27T03:50:05Z\u0026#34;, \u0026#34;last_seen\u0026#34;: \u0026#34;2023-01-11T09:34:41Z\u0026#34;, \u0026#34;count\u0026#34;: 11, \u0026#34;name\u0026#34;: \u0026#34;Submission on VT\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-20T15:58:23.694985Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-03-20T15:58:23.704958Z\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;attributes\u0026#34;: { \u0026#34;source_vendor\u0026#34;: \u0026#34;VirusTotal\u0026#34; }, \u0026#34;involved_entity\u0026#34;: \u0026#34;7c208f04-54f6-441c-8823-a125ee8d9151\u0026#34; } ], \u0026#34;relations\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;27f61e7e-0b3a-44fc-842c-2933c160105e\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;documents\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-18T20:36:40.821695Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;source_vendor\u0026#34;: \u0026#34;OTX Alien Vault\u0026#34; }, \u0026#34;obj_from\u0026#34;: \u0026#34;729c6a82-9fc7-4411-abcf-ebfb30d54e24\u0026#34;, \u0026#34;obj_to\u0026#34;: \u0026#34;7c208f04-54f6-441c-8823-a125ee8d9151\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;55d2bdac-41d9-4cb2-8a4e-acb101166bb7\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;documents\u0026#34;, \u0026#34;description\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2023-03-18T20:36:40.837011Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;source_vendor\u0026#34;: \u0026#34;OTX Alien Vault\u0026#34; }, \u0026#34;obj_from\u0026#34;: \u0026#34;1b994b04-870f-458a-8cb3-a3e3502e514d\u0026#34;, \u0026#34;obj_to\u0026#34;: \u0026#34;7c208f04-54f6-441c-8823-a125ee8d9151\u0026#34; }, [redacted] ], \u0026#34;graph\u0026#34;: \u0026#34;flowchart [redacted Mermaid diagram]\u0026#34; } `}).add({id:37,href:"/docs/colander/",title:"Colander",description:"Colander",content:""}).add({id:38,href:"/docs/pirogue/",title:"PiRogue",description:"PiRogue",content:""}).add({id:39,href:"/docs/recipes/pirogue-without-ethernet-connection/",title:"PiRogue without ethernet connection",description:`This is the translation in English of a tutorial originally written by Thomas Fourmeux, a French librarian. Follow him on Twitter!
Context # This tutorial is for using the PiRogue in a situation where you don\u0026rsquo;t have a wired connection to the Internet (such as in a car). Thanks to a travel router, you will be able to share (via USB) your smartphone\u0026rsquo;s LTE/4G connection with the PiRogue.
Requirements # In this situation, you need the following hardware:`,content:`This is the translation in English of a tutorial originally written by Thomas Fourmeux, a French librarian. Follow him on Twitter!
Context # This tutorial is for using the PiRogue in a situation where you don\u0026rsquo;t have a wired connection to the Internet (such as in a car). Thanks to a travel router, you will be able to share (via USB) your smartphone\u0026rsquo;s LTE/4G connection with the PiRogue.
Requirements # In this situation, you need the following hardware:
a PiRogue (obviously) a smartphone with a LTE/4G connection to the Internet a travel router GL-AR750 available on Amazon a laptop Setup # Follow these steps to connect all the pieces together:
connect your PiRogue to your travel router with an ethernet cable power on both the travel router and the PiRogue connect your smartphone (the one sharing its Internet connection) with a USB cable to the travel router connect your laptop to the travel router\u0026rsquo;s Wi-Fi network named GL-AR750S-XXX, the password is goodlife (it is also written on the back of the travel router) on your laptop, open the travel router\u0026rsquo;s administration panel in a Web browser, it is usually accessible at http://192.168.8.1 👉 Note that you have to enable the USB tethering in the settings of your smartphone. Configure the travel router # When you first connect, you must set the language and administrator password to secure access to the router.
In the Internet tab, enable connection sharing as follows: We can connect the router in LAN via a cable, use the router in repeater mode, connect a 4G dongle or in connection sharing mode with a smartphone. It is this last option that interests us. After connecting the smartphone via USB, the router interface detects the device in the Sharing section with the usb0 device and proposes to connect the two devices. We establish the connection by clicking on Connect.
Once the connection is established, the router shows the network configuration with its IP address, the netmask, the default gateway and the default DNS server.
Get the PiRogue\u0026rsquo;s IP address # To be able to connect to your PiRogue dashboard, you need its IP address. To find it, just go to the Clients tab of the router\u0026rsquo;s administration panel to list all the devices connected to it. The PiRogue is indicated in the column Wired device with the name raspberrypi.
Finally, the PiRogue network is operational. You can connect to the PiRogue\u0026rsquo;s dashboard as you usually do just by browsing its IP address on port 3000 in your Web browser. The IP address is listed on the Clients page of the router, it should look like 192.168.8.xxx
`}).add({id:40,href:"/docs/recipes/device-forensic-with-mvt/",title:"Device forensic with MVT",description:`Disclaimer # Mobile Verification Toolkit (MVT) is a tool to facilitate the consensual forensic analysis of Android and iOS devices, for the purpose of identifying traces of compromise.
MVT\u0026rsquo;s purpose is not to facilitate adversarial forensics of non-consenting individuals\u0026rsquo; devices. The use of MVT and derivative products to extract and/or analyse data originating from devices used by individuals not consenting to the procedure is explicitly prohibited in the license.
MVT a.`,content:`Disclaimer # Mobile Verification Toolkit (MVT) is a tool to facilitate the consensual forensic analysis of Android and iOS devices, for the purpose of identifying traces of compromise.
MVT\u0026rsquo;s purpose is not to facilitate adversarial forensics of non-consenting individuals\u0026rsquo; devices. The use of MVT and derivative products to extract and/or analyse data originating from devices used by individuals not consenting to the procedure is explicitly prohibited in the license.
MVT a.k.a Mobile Verification Toolkit is developed and maintained by Amnesty International. This tool is pre-installed on your PiRogue but not maintained by the PTS team.
Official documentation →
Preliminaries # Before using MVT, be sure to pull the IOCs from Amnesty International\u0026rsquo;s git repository.
To do so, on your PiRogue, run the following command
mvt-android download-iocs Forensic of an Android device # First of all, you have to connect the target device with USB to your PiRogue. On the device, you have to enable ADB in the Developer Settings. If the device is rooted, you should enable root for ADB only. On the Android device select Transfer files by taping on Android System - USB charging (in the list of notifications).
NB: all the following commands have to be executed on your PiRogue.
Then, run the following command:
adb devices It should give an output similar to:
* daemon not running; starting now at tcp:5037 * daemon started successfully List of devices attached 2[redacted]e device Before running MVT, you have to kill the ADB server
adb kill-server Finally, launch MVT and follow its official documentation.
Below is an example of use of MVT.
mvt-android check-adb -f -o mvt-demo It might produce an output similar to
Forensic of an iOS device # Prepare the iOS device to be analyzed # First of all, you have to connect the target device with USB to your PiRogue.
NB: all the following commands have to be executed on your PiRogue.
Once connected, start the USB mixer by running the following command
usbmuxd ⚠️ If usbmuxd is not found, install libimobiledevice. Run the following command
sudo apt install libimobiledevice-utils
The iOS device may be asking you if you trust the connected computer, trust it. Then, check if your iOS device is correctly recognized by running
ideviceinfo The previous command would print various information regarding your device.
Backup the iOS device # In order to get as many information as possible, you have to turn backup encryption on by running
idevicebackup2 backup encryption on -i Then backup the iOS device by running
idevicebackup2 backup --full backup/ Once done, you can unplug the iOS device. Run ls -l backup to get the name of the backup.
Analyze the backup # Run the following command to decrypt the backup
mvt-ios decrypt-backup -p \u0026lt;backup password\u0026gt; -d decrypted backup/\u0026lt;backup name\u0026gt; For more details and options, check the MVT documentation regarding the backup password. If you have backed up this phone using iTunes, the backup password is the same as the one you provided in iTunes.
Next, analyze the backup with mvt-ios
mvt-ios check-backup -o checked decrypted Finally, check the the results listed in the checked folder
ls -l checked The folder checked contains several JSON files. Any IOC matches are stored in JSON files suffixed by _detected.
`}).add({id:41,href:"/docs/recipes/add-your-own-suricata-rules-to-pirogue/",title:"Add your own suricata rules to PiRogue",description:`This is a friendly contribution written by evilcel3ri, security researcher also developer for Pithus. Follow him on Twitter!
Add your own suricata rules to PiRogue # You need:
SSH access to your PiRogue Github knowledge Optional: if you want access to ET PRO you would need your Oink code The easiest way to manage your Suricata rules is to have them on a Github repository or on a Web directory that can be checked out by suricata-update.`,content:`This is a friendly contribution written by evilcel3ri, security researcher also developer for Pithus. Follow him on Twitter!
Add your own suricata rules to PiRogue # You need:
SSH access to your PiRogue Github knowledge Optional: if you want access to ET PRO you would need your Oink code The easiest way to manage your Suricata rules is to have them on a Github repository or on a Web directory that can be checked out by suricata-update. Manually adding rules directly to the PiRogue is not recommended as it might get overwritten by an update.
Write your rules according to Suricata\u0026rsquo;s documentation. Bare in mind, the rules you want to write are alert ones. Set them up on a Github repository (or a Web directory) that can be reached by your PiRogue.
After being connected to your PiRogue.
Add your new source in this fashion:
sudo suricata-update add-source YOUR_NAME URL_TO_THE_DOT_RULES Run
sudo suricata-update and then
sudo suricatasc -c reload-rules and your rules must be updated and taken into account 🙂
Example with Abuse.ch SSL blocklist # If you want to add the Abuse.ch SSL blocklist, run the following commands:
sudo suricata-update add-source SSLBL https://sslbl.abuse.ch/blacklist/sslblacklist.rules sudo suricata-update sudo suricatasc -c reload-rules Add an already published rule set such as ET Pro # While connected to your PiRogue: Run
sudo suricata-update enable-source et/pro insert your oink-code when prompted and finally run
sudo suricata-update sudo suricatasc -c reload-rules In both cases, the PiRogue will grab the new version of your rules on a daily basis.
`}).add({id:42,href:"/docs/recipes/turn-a-regular-pc-into-a-pirogue/",title:"Turn a regular PC into a PiRogue",description:`This recipe is dedicated to intrepid users 😎
Requirements # To follow this recipe we need:
a PC with one Ethernet interface, one wireless interface and Debian 11 freshly installed the wireless interface has to support the AP mode (access-point mode) the PC is connected to our local network via its Ethernet adapter the PC has an Internet connection ⚠️ Don\u0026rsquo;t install any desktop environment. Prepare the system # We will do everything by command line so, we connect to our PC and run the following command to upgrade it:`,content:`This recipe is dedicated to intrepid users 😎
Requirements # To follow this recipe we need:
a PC with one Ethernet interface, one wireless interface and Debian 11 freshly installed the wireless interface has to support the AP mode (access-point mode) the PC is connected to our local network via its Ethernet adapter the PC has an Internet connection ⚠️ Don\u0026rsquo;t install any desktop environment. Prepare the system # We will do everything by command line so, we connect to our PC and run the following command to upgrade it:
sudo apt update sudo apt dist-upgrade Then install iw to check if the wireless interface supports the AP mode:
sudo apt install iw run iw listand scroll through its output to check if the wireless interface supports the AP mode. If so, it should look like
Install the PiRogue packages # Next, we have to add the PTS PPA (repositoty containing all PiRogue packages) by running
sudo curl -o /etc/apt/sources.list.d/pirogue.list https://pts-project.org/debian-12/pirogue.list sudo curl -o /etc/apt/trusted.gpg.d/pirogue.asc https://pts-project.org/debian-12/Key.gpg sudo apt update Finally install the PiRogue features:
sudo apt install pirogue-base Check if everything runs properly # To check how healthy our PiRogue is, run
pirogue-ctl status If we see everything in a mix of purple and green, congrats! If not, join the Discord channel to get help.
`}).add({id:43,href:"/docs/recipes/how-to-intercept-and-decrypt-tls-traffic/",title:"How to intercept and decrypt TLS traffic",description:`This recipe is dedicated to intrepid users 😎
PiRogue comes with a pirogue-intercept-* helpers to help you intercept encrypted TLS traffic from applications, even in presence of TLS certificate pinning.
These helpers are meant to:
capture the network traffic instrument a specific application or any launched application Requirements # To follow this recipe, you need:
an up-to-date PiRogue a rooted Android device Procedure # First, SSH onto your PiRogue. Attach your smartphone to the PiRogue through USB and make sure \u0026ldquo;USB debugging\u0026rdquo; is on and working.`,content:`This recipe is dedicated to intrepid users 😎
PiRogue comes with a pirogue-intercept-* helpers to help you intercept encrypted TLS traffic from applications, even in presence of TLS certificate pinning.
These helpers are meant to:
capture the network traffic instrument a specific application or any launched application Requirements # To follow this recipe, you need:
an up-to-date PiRogue a rooted Android device Procedure # First, SSH onto your PiRogue. Attach your smartphone to the PiRogue through USB and make sure \u0026ldquo;USB debugging\u0026rdquo; is on and working.
Make sure to enable ADB Transfer files by clicking on the Android System notification.
Your browser does not support the video tag. Then check if the PiRogue sees your device by running the command:
adb devices You should see your device listed. If not, be sure to use the right USB cable for your device. If the issue remains, check that you have the rights to interact with USB devices. To do so, run the command groups to list the groups you belong to and check if the group plugdev is listed. If not, execute the following command sudo usermod -aG plugdev $LOGNAME and reboot.
Identify and install the application # Android applications are identified by their package name. As an example, the French weather forecast application is fr.meteo. You can get the package name either from Google Play URL or from any tool analyzing Android apps such as Pithus, Virus Total, etc. In our example, the Google Play URL looks like https://play.google.com/store/apps/details?id=fr.meteo, the package name of the application is specified after id=.
Once you have identified the application you want to analyze, you have to download and install it on your target device. If you need to download the application from Google Play, we recommend to use apkeep (not installed by default on PiRogue).
Finally, to install the application, run the following command:
adb install \u0026lt;APK file\u0026gt; If your application contains multiple APKs (like in XAPK), use the command adb install-multiple \u0026lt;list all apks\u0026gt;.
Don\u0026rsquo;t launch the application.
Instrument and intercept # Once the application to be analyzed is installed on your Android device, connect your device to the PiRogue Wi-Fi network and run the following command:
sudo pirogue-intercept-gated -o \u0026lt;path to the output directory\u0026gt; Adapt the command according to your output directory of choice. Once started and showing Waiting for data, manually launch the application you want to analyze.
Now, interact with the application freely. When you are done interacting with the app, hit Ctrl+C on your keyboard to stop interception.
⚠️ Make sure that the application you want to be analyzed is not running in background. You can, for example, force stop it in Settings \u0026gt; Apps, select the application and click on Stop. Decrypt the traffic # If we run the previous command with sudo, we have to fix the permissions of generated files by running:
chown -R pi:pi \u0026lt;path to the output directory\u0026gt; Then enter the output directory with:
cd \u0026lt;path to the output directory\u0026gt; Next, we generate a PCAPNG file containing both the TLS keys and the captured traffic:
editcap --inject-secrets tls,sslkeylog.txt traffic.pcap decrypted.pcapng Next, we export the decrypted traffic in JSON:
tshark -2 -T ek --enable-protocol communityid -Ndmn -r decrypted.pcapng \u0026gt; traffic.json Finally, to view the decrypted traffic, run:
pirogue-view-tls -i traffic.json -t socket_trace.json ⚠️ The display of the stack trace has been added to pirogue-cli in version 1.0.5. Be sure to upgrade your PiRogue. If you face any issue, join the Discord channel to get help.
Generated files # The commands pirogue-intercept-single and pirogue-intercept-gated generate the following files:
aes_info.json contains all AES and RSA encryption/decryption operation with both cleartext and cyphertext device.json contains various information about the device such as IMEI, Android version experiment.json contains timing information such as the start and end date of the experiment screen.mp4 contains the video recording of the device\u0026rsquo;s screen socket_trace.json contains the stack trace of all operations on sockets (open, close, read, write\u0026hellip;) sslkeylog.txt contains the TLS encryption keys in the NSS key log format traffic.pcap contains the entire network traffic captured during the experiment NB: you can open the PCAP file with Wireshark and specify the key log file in Settings \u0026gt; Protocols \u0026gt; TLS. This way, Wireshark will automatically decrypt TLS traffic.
`}).add({id:44,href:"/docs/recipes/export-pirogue-data/",title:"Export PiRogue data",description:`This is the translation in English from Spanish of a tutorial originally written by niculcha.
What is PiRogue # For a few months we have been testing PiRogue to perform network traffic analysis mainly on cell phones, so PiRogue becomes a super complete tool that contains many applications that help us to perform network traffic analysis, this hardware and software helps us to perform monitoring on intervention and network traffic.`,content:`This is the translation in English from Spanish of a tutorial originally written by niculcha.
What is PiRogue # For a few months we have been testing PiRogue to perform network traffic analysis mainly on cell phones, so PiRogue becomes a super complete tool that contains many applications that help us to perform network traffic analysis, this hardware and software helps us to perform monitoring on intervention and network traffic.
One of the big challenges in forensic analysis is to know how to search the results, PiRogue deletes the data every 5 days for security reasons but to do a further analysis we need to extract the alerts and flows as a result of the analysis, to export the data we need to do the following steps.
How to export data # First, connect to your PiRogue with SSH:
ssh -p22 pi@\u0026lt;PiRogue IP address\u0026gt; Then, export alert data in a CSV file:
influx -database \u0026#39;suricata\u0026#39; -execute \u0026#39;SELECT * FROM \u0026#34;suricata\u0026#34;.\u0026#34;suricata_5d\u0026#34;.\u0026#34;alert\u0026#34;\u0026#39; -format \u0026#39;csv\u0026#39; \u0026gt; alerts-\`date +\u0026#34;%Y-%m-%d\u0026#34;\`.csv Export flow data too:
influx -database \u0026#39;flows\u0026#39; -execute \u0026#39;SELECT * FROM \u0026#34;flows\u0026#34;.\u0026#34;flows_5d\u0026#34;.\u0026#34;flow\u0026#34;\u0026#39; -format \u0026#39;csv\u0026#39; \u0026gt; flows-\`date +\u0026#34;%Y-%m-%d\u0026#34;\`.csv Finally, copy 2 generated CSV files from PiRogue to your computer using scp. On your computed, use the following command:
scp pi@\u0026lt;iRogue IP address\u0026gt;:\u0026lt;path of the CSV file\u0026gt; . Once you have retrieved your CSV files, you can open them with Excel, LibreOffice or any other software supporting CVS format.
Going further # The queries listed above are pretty simple but you can adapt them to your specific need, check out the influxdb documentation.
You can refine your request by filtering the following fields of the flows database:
time: timestamp in nanoseconds on first flow bidirectional packet application_category_name: nDPI detected application category name application_name: nDPI detected application name bidirectional_bytes: flow bidirectional bytes accumulator bidirectional_duration_ms: flow bidirectional duration in milliseconds city: city determined by geoip based on the remote IP address community_id: community ID community_id_b64: community ID encoded in base64 country: country name determined by geoip based on the remote IP address country_iso: country ISO code determined by geoip based on the remote IP address dst2src_bytes: flow destination to source bytes accumulator dst_ip: destination IP address string representation dst_mac: destination MAC address string representation dst_port: transport layer destination port latitude: latitude determined by geoip based on the remote IP address longitude: longitude determined by geoip based on the remote IP address requested_server_name: requested server name (SSL/TLS, DNS, HTTP) src2dst_bytes: flow source to destination bytes accumulator src_ip: source IP address string representation src_mac: source MAC address string representation src_port: transport layer source port You can refine your request by filtering the following fields of the suricata database:
time: timestamp in nanoseconds on detection alert_category: category of the triggered rule alert_severity: alert severity alert_signature: signature of the triggered rule alert_signature_id: unique identifier of the triggered rule app_proto: network protocol (dns, http\u0026hellip;) community_id: community ID community_id_b64: community ID encoded in base64 dest_ip: destination IP address string representation dest_port: transport layer destination port in_iface: network interface name proto: transport protocol (UDP, TCP) src_ip: source IP address string representation src_port: transport layer source port `}).add({id:45,href:"/docs/prologue/",title:"Prologue",description:"Prologue",content:""}).add({id:46,href:"/docs/",title:"Documentation",description:"Documentation",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()